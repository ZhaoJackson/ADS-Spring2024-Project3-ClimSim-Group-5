{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a3747c3-fed4-4671-bfbd-3919a17b0de9",
   "metadata": {},
   "source": [
    "## 0. Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e001998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Input, SimpleRNN\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef7098",
   "metadata": {},
   "source": [
    "## 1. Load the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb18c3",
   "metadata": {},
   "source": [
    "For the project, we provide a training set with 50000 images in the directory `../data/images/` with:\n",
    "- noisy labels for all images provided in `../data/noisy_label.csv`;\n",
    "- clean labels for the first 10000 images provided in `../data/clean_labels.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "112ee347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "\n",
    "# load the images\n",
    "n_img = 50000\n",
    "n_noisy = 40000\n",
    "n_clean_noisy = n_img - n_noisy\n",
    "imgs = np.empty((n_img,32,32,3))\n",
    "for i in range(n_img):\n",
    "    img_fn = f'../data/images/{i+1:05d}.png'\n",
    "    imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# load the labels\n",
    "clean_labels = np.genfromtxt('../data/clean_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "noisy_labels = np.genfromtxt('../data/noisy_labels.csv', delimiter=',', dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4146da",
   "metadata": {},
   "source": [
    "For illustration, we present a small subset (of size 8) of the images with their clean and noisy labels in `clean_noisy_trainset`. You are encouraged to explore more characteristics of the label noises on the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfd4d838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean labels:\n",
      " frog truck truck  deer   car   car  bird horse\n",
      "Noisy labels:\n",
      "  cat   dog truck  frog   dog  ship  bird  deer\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# Add labels\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(2,4,1)\n",
    "ax1.imshow(imgs[0]/255)\n",
    "ax2 = fig.add_subplot(2,4,2)\n",
    "ax2.imshow(imgs[1]/255)\n",
    "ax3 = fig.add_subplot(2,4,3)\n",
    "ax3.imshow(imgs[2]/255)\n",
    "ax4 = fig.add_subplot(2,4,4)\n",
    "ax4.imshow(imgs[3]/255)\n",
    "ax1 = fig.add_subplot(2,4,5)\n",
    "ax1.imshow(imgs[4]/255)\n",
    "ax2 = fig.add_subplot(2,4,6)\n",
    "ax2.imshow(imgs[5]/255)\n",
    "ax3 = fig.add_subplot(2,4,7)\n",
    "ax3.imshow(imgs[6]/255)\n",
    "ax4 = fig.add_subplot(2,4,8)\n",
    "ax4.imshow(imgs[7]/255)\n",
    "\n",
    "# The class-label correspondence\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# print clean labels\n",
    "print('Clean labels:')\n",
    "print(' '.join('%5s' % classes[clean_labels[j]] for j in range(8)))\n",
    "# print noisy labels\n",
    "print('Noisy labels:')\n",
    "print(' '.join('%5s' % classes[noisy_labels[j]] for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43fcf58",
   "metadata": {},
   "source": [
    "## 2. The predictive model\n",
    "\n",
    "We consider a baseline model directly on the noisy dataset without any label corrections. RGB histogram features are extracted to fit a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b71e35",
   "metadata": {},
   "source": [
    "### 2.1. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59a097c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# RGB histogram dataset construction\n",
    "no_bins = 6\n",
    "bins = np.linspace(0,255,no_bins) # the range of the rgb histogram\n",
    "target_vec = np.empty(n_img)\n",
    "feature_mtx = np.empty((n_img,3*(len(bins)-1)))\n",
    "i = 0\n",
    "for i in range(n_img):\n",
    "    # The target vector consists of noisy labels\n",
    "    target_vec[i] = noisy_labels[i]\n",
    "    \n",
    "    # Use the numbers of pixels in each bin for all three channels as the features\n",
    "    feature1 = np.histogram(imgs[i][:,:,0],bins=bins)[0] \n",
    "    feature2 = np.histogram(imgs[i][:,:,1],bins=bins)[0]\n",
    "    feature3 = np.histogram(imgs[i][:,:,2],bins=bins)[0]\n",
    "    \n",
    "    # Concatenate three features\n",
    "    feature_mtx[i,] = np.concatenate((feature1, feature2, feature3), axis=None)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26c76f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# Train a logistic regression model \n",
    "clf = LogisticRegression(random_state=0).fit(feature_mtx, target_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084dc3ea",
   "metadata": {},
   "source": [
    "For the convenience of evaluation, we write the following function `predictive_model` that does the label prediction. **For your predictive model, feel free to modify the function, but make sure the function takes an RGB image of numpy.array format with dimension $32\\times32\\times3$  as input, and returns one single label as output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd3fd7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "def baseline_model(image):\n",
    "    '''\n",
    "    This is the baseline predictive model that takes in the image and returns a label prediction\n",
    "    '''\n",
    "    feature1 = np.histogram(image[:,:,0],bins=bins)[0]\n",
    "    feature2 = np.histogram(image[:,:,1],bins=bins)[0]\n",
    "    feature3 = np.histogram(image[:,:,2],bins=bins)[0]\n",
    "    feature = np.concatenate((feature1, feature2, feature3), axis=None).reshape(1,-1)\n",
    "    return clf.predict(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05286e56",
   "metadata": {},
   "source": [
    "### 2.2 Model I - CNN Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4187829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacksonzhao/miniconda3/envs/5243_proj3/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> \n",
       "\n",
       " batch_normalization              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \n",
       "\n",
       " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
       "\n",
       " batch_normalization_2            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> \n",
       "\n",
       " batch_normalization_3            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m896\u001b[0m \n",
       "\n",
       " batch_normalization              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m128\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m18,496\u001b[0m \n",
       "\n",
       " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m73,856\u001b[0m \n",
       "\n",
       " batch_normalization_2            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)             \u001b[38;5;34m295,168\u001b[0m \n",
       "\n",
       " batch_normalization_3            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)               \u001b[38;5;34m1,024\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dropout_3 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m131,200\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                      \u001b[38;5;34m1,290\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">522,826</span> (1.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m522,826\u001b[0m (1.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">521,866</span> (1.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m521,866\u001b[0m (1.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "nn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac191e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3deb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do a model training based on the first 10000 imgs with cleaned label (8000-2000)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# n_train_img = 10000\n",
    "n_train_img = 50000\n",
    "target_vec = np.empty(n_train_img)\n",
    "i = 0\n",
    "\n",
    "for i in range(n_train_img):\n",
    "\n",
    "    # target_vec[i] = clean_labels[i]\n",
    "    target_vec[i] = noisy_labels[i]\n",
    "\n",
    "\n",
    "feature = imgs[:n_train_img]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b10ec86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_images = np.array([cv2.resize(img, (32, 32)) for img in feature_mtx])\n",
    "# target_vec = to_categorical(target_vec, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e044902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 5., 9., ..., 9., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f2c67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m   4/1250\u001b[0m \u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.0814 - loss: 4.2359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacksonzhao/miniconda3/envs/5243_proj3/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 34ms/step - accuracy: 0.1071 - loss: 2.4179 - val_accuracy: 0.1010 - val_loss: 2.3025\n",
      "Epoch 2/3\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 35ms/step - accuracy: 0.0991 - loss: 2.3030 - val_accuracy: 0.1145 - val_loss: 44.4354\n",
      "Epoch 3/3\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - accuracy: 0.1198 - loss: 2.2931 - val_accuracy: 0.1189 - val_loss: 6.2556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x307691b50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNL0lEQVR4nO3deVgVdf//8ScgBxTEFXfFFXMr1xSXtDRMhdxyLbLtvrPdvKs7b7OsLPPbZmZa9uuuLLfK3dwwtTSXbkla1HJJxQUDTUUgQWB+f0yeREA5cGDO8npcF1fjmTln3tNx4tXMZz5vH8MwDERERETcnK/VBYiIiIg4g0KNiIiIeASFGhEREfEICjUiIiLiERRqRERExCMo1IiIiIhHUKgRERERj6BQIyIiIh6hjNUFlKacnByOHz9O+fLl8fHxsbocERERKQTDMDh37hy1atXC17fg6zFeFWqOHz9O3bp1rS5DREREiuDIkSPUqVOnwPVeFWrKly8PmP9SQkJCLK5GRERECiMlJYW6devaf48XxKtCzcVbTiEhIQo1IiIibuZqQ0c0UFhEREQ8gkKNiIiIeASFGhEREfEIXjWmpjCys7O5cOGC1WV4PT8/P8qUKaNH70VEpNAUai6RmprK0aNHMQzD6lIEKFeuHDVr1sRms1ldioiIuAGFmr9kZ2dz9OhRypUrR2hoqK4QWMgwDDIzM0lOTubgwYM0adLkipMtiYiIgEKN3YULFzAMg9DQUMqWLWt1OV6vbNmy+Pv7c/jwYTIzMwkMDLS6JBERcXH639/L6AqN69DVGRERcYR+a4iIiIhHUKgRERERj6BQIyIiIh5BoUZEREQ8gp5+EhERkeJ7/nkwDHj2WbDoQQ9dqSmIYUBamjU/Dk7+t3r1arp27UrFihWpUqUKUVFRHDhwwL7+6NGjDB8+nMqVKxMUFET79u3Zvn27ff2yZcto3749gYGBVK1alUGDBjntX6OIiHiBRYtg4kQz2Kxfb1kZulJTkPR0CA62Zt+pqRAUVOjN09LSGDt2LK1atSItLY1nn32WgQMHEh8fT3p6Ot27d6d27dosW7aMGjVq8P3335OTkwPAl19+yaBBgxg/fjyffPIJmZmZfPnllyV1ZCIi4ml++gnuvNNcHjMGevWyrBQfw4t6AqSkpFChQgXOnj1LSEhIrnXnz5/n4MGDNGjQwJzoLS3NbULN5ZKTk6lWrRo//fQTW7Zs4YknnuDQoUNUrlw5z7adO3emYcOGfPrpp8WpuETk+U5ERMS1nDoFHTrAwYPQsyesXg1lnH+95Eq/vy+lKzUFKVfODBdW7dsBBw4cYMKECWzbto2TJ0/ar8IkJCQQHx9PmzZt8g00APHx8fzjH/8odskiIuJlsrJg2DAz0DRoAAsWlEigcYRCTUF8fIp1taQ0RUdHU7duXd5//31q1apFTk4OLVu2JDMz86otH9QSQkREiuTJJ+Grr8zflUuXQpUqVlekgcLu7tSpU+zZs4dnnnmGnj170qxZM06fPm1ff+211xIfH88ff/yR7/uvvfZavvrqq9IqV0REPMHHH8PUqeby7NnQqpWl5VykUOPmKlWqRJUqVZg1axb79+9n/fr1jB071r5+xIgR1KhRgwEDBvDtt9/y22+/sXDhQrZu3QrAc889x7x583juuefYs2cPP/30E//3f/9n1eGIiIir274d7r/fXH72WXChJ2YVatycr68v8+fPJy4ujpYtW/L444/z6quv2tfbbDbWrl1LtWrV6Nu3L61ateKVV17Bz88PgB49evD555+zbNkyWrduzU033ZTrcW8RERG748dh4EDIyID+/eG556yuKBc9/fQXPWnjevSdiIi4kIwM6NEDtm2DFi1g61YoX75Udl3Yp590pUZERESuzDDggQfMQFOpkjkwuJQCjSMUakREROTKpk+HDz802x8sWACNGlldUb4UakRERKRg69fD44+by6++CjffbG09V6BQIyIiIvk7eBCGDIHsbIiJ+TvcuCiFGhEREckrNRUGDIA//oD27eG998yJaV2YQo2IiIjkZhhw113w449QvTosXgxuMAO9Qo2IiIjk9tJLsHAh+PvDokVQp47VFRWKQo2IiIj8bdkymDDBXJ45Ezp3trYeByjUiIiIiGn3brjjDnP5oYfg3nutrcdBCjVern79+ky92JRMRES81+nTZuuDc+ege3d4802rK3KYQo2IiIi3y8qC4cNh/34IC4PPPzfH07gZhRoRERFvN24crF0L5crBkiUQGmp1RUWiUFMAwzBIy0yz5KewPUbfe+89ateuTU5OTq7Xb731VkaNGsWBAwfo378/1atXJzg4mA4dOrBu3boi/zt54403aNWqFUFBQdStW5cHH3yQ1NTUXNt8++23dO/enXLlylGpUiV69+7N6dOnAcjJyWHKlCk0btyYgIAA6tWrx0svvVTkekRExAnmzIHXXjOXP/wQWre2tJziKGN1Aa4q/UI6wZODLdl36rhUgmxBV91uyJAhPProo2zYsIGePXsCcPr0adasWcPy5ctJTU2lb9++TJo0icDAQD7++GOio6P59ddfqVevnsN1+fr6Mm3aNOrXr8/Bgwd58MEHeeqpp5gxYwYA8fHx9OzZk3vuuYdp06ZRpkwZNmzYQHZ2NgDjxo3j/fff580336Rr164kJibyyy+/OFyHiIg4yY4dcN995vJ//gNDh1pbTzH5GIW9LOABrtS6/Pz58xw8eJAGDRoQGBhIWmaay4cagP79+1O1alU++OADAGbNmsVzzz3H0aNH8fPzy7N9ixYteOCBB3j44YcBc6DwmDFjGDNmjMN1fv755zzwwAOcPHkSgJEjR5KQkMDmzZvzbHvu3DlCQ0OZPn069108ga7i8u9ERESc6MQJ6NABjh6FqCiz87ava97AudLv70vpSk0ByvmXI3Vc6tU3LKF9F9btt9/OP//5T2bMmEFAQABz5sxh+PDh+Pn5kZaWxvPPP8+KFSs4fvw4WVlZ/PnnnyQkJBSprg0bNvDyyy+ze/duUlJSyMrK4vz586SlpREUFER8fDxDhgzJ97179uwhIyPDfkVJREQslJkJt91mBpprroFPP3XZQOMIhZoC+Pj4FPpqiZWio6PJycnhyy+/pEOHDmzatIk33ngDgCeffJI1a9bw2muv0bhxY8qWLcttt91GZmamw/s5fPgwffv2ZfTo0bz44otUrlyZzZs3c++993LhwgUAyl5hCu0rrRMRkVJkGPDww/Dtt1ChgnmFpkIFq6tyCvePZV6ubNmyDBo0iDlz5jBv3jzCw8Np164dAJs2beKuu+5i4MCBtGrViho1anDo0KEi7WfHjh1kZWXx+uuv06lTJ8LDwzl+/Hiuba699lq++uqrfN/fpEkTypYtW+B6EREpJe++C++/bzannDcPwsOtrshpdKXGA9x+++1ER0eza9cu7rg4EyTQuHFjFi1aRHR0ND4+PkyYMCHPk1KF1ahRI7Kysnj77beJjo7m22+/5d133821zbhx42jVqhUPPvggo0ePxmazsWHDBoYMGULVqlX597//zVNPPYXNZqNLly4kJyeza9cu7nWzGStFRNzWN9/Ao4+ay6+8An36WFuPk+lKjQe46aabqFy5Mr/++isjR460v/7mm29SqVIlOnfuTHR0NL1796Zt27ZF2kfr1q154403mDJlCi1btmTOnDlMnjw51zbh4eGsXbuWH374geuvv56IiAiWLl1KmTJmdp4wYQL/+te/ePbZZ2nWrBnDhg0jKSmp6AcuIiKFd/iwOY4mKwtGjIAnn7S6IqfT009/0ZM2rkffiYiIk6SnQ5cuEB8PbdrA5s3mRHtuorBPP+lKjYiIiCczDLjnHjPQhIaaMwa7UaBxhEKNADBnzhyCg4Pz/WnRooXV5YmISFFNmQILFkCZMrBwIRRh8lV3oYHCApitFTp27JjvOn83bGomIiLAypXmTMEAb78N3bpZW08JU6gRAMqXL0/58uWtLkNERJzl11/NAcGGAfffD6NHW11RidPtp8t40bhpl6fvQkSkiM6cgVtvhZQU6NoVpk2zuqJSoVDzl4t9kooy266UjPT0dEC3v0REHJKdDbffDnv3Qt268MUXYLNZXVWp0O2nv5QpU4Zy5cqRnJyMv78/vh7QA8NdGYZBeno6SUlJVKxYMd/GnCIiUoAJE8yxNIGBsHgxVK9udUWlRqHmLz4+PtSsWZODBw9y+PBhq8sRoGLFitSoUcPqMkRE3MeCBXBxYtQPPoC/2uZ4C4WaS9hsNpo0aaJbUC7A399fV2hERByxcyfcfbe5/NRTcMkM895CoeYyvr6+mr1WRETcS1ISDBgAf/4Jt9wCL79sdUWW0MARERERd3bhAgwZAgkJ0KSJ2XnbS690FynUzJgxw96Pp127dmzatKnAbRMTExk5ciRNmzbF19eXMWPG5Nnm/fffp1u3blSqVIlKlSrRq1cvvvvuu2LtV0RExCuMGWN23y5fHpYuhYoVra7IMg6HmgULFjBmzBjGjx/Pzp076datG3369CEhISHf7TMyMggNDWX8+PFcd911+W6zceNGRowYwYYNG9i6dSv16tUjMjKSY8eOFXm/IiIiHm/WLJgxA3x8YM4caNbM6oos5XCX7o4dO9K2bVtmzpxpf61Zs2YMGDCAyRdHXBegR48etG7dmqlTp15xu+zsbCpVqsT06dO58847i73fiwrb5VNERMTlffst3HijefvppZf+bofggUqkS3dmZiZxcXFERkbmej0yMpItW7YUrdJ8pKenc+HCBSpXrlyq+xUREXELR47A4MF/j6cZN87qilyCQ08/nTx5kuzsbKpfNpFP9erVOXHihNOKevrpp6lduza9evUq1n4zMjLIyMiw/zklJcVpNYqIiFjizz9h4ED4/Xe49lr48EPz9pMUbaCwz2X/8gzDyPNaUf3f//0f8+bNY9GiRXkerXZ0v5MnT6ZChQr2n7p16zqlRhEREUsYBvzjHxAXB1WqmAODg4KsrsplOBRqqlatip+fX56rI0lJSXmuohTFa6+9xssvv8zatWu59tpri73fcePGcfbsWfvPkSNHil2jiIiIZd54wxwQ7Odn9nSqX9/qilyKQ6HGZrPRrl07YmNjc70eGxtL586di1XIq6++yosvvsjq1atp3769U/YbEBBASEhIrh8RERG3tGaNOVMwwNSp0KOHldW4JIdnFB47diwxMTG0b9+eiIgIZs2aRUJCAqNHjwbMqyPHjh1j9uzZ9vfEx8cDkJqaSnJyMvHx8dhsNpo3bw6Yt5wmTJjA3LlzqV+/vv2KTHBwMMHBwYXar4iIiMfatw+GD4ecHLj3XnjoIasrck1GEbzzzjtGWFiYYbPZjLZt2xpff/21fd2oUaOM7t2759oeyPMTFhZmXx8WFpbvNs8991yh91sYZ8+eNQDj7Nmzjh6yiIiINc6eNYxmzQwDDCMiwjDOn7e6olJX2N/fDs9T4840T42IiLiVnBzzSadly6BWLdixA2rWtLqqUlci89SIiIhIKZo40Qw0AQGweLFXBhpHKNSIiIi4oi++gBdfNJdnzYLrr7e2HjegUCMiIuJqfvwRRo0yl8eOhb9aBsmVKdSIiIi4kpMnoX9/SE+Hm2+GKVOsrshtKNSIiIi4igsXYOhQOHQIGjaE+fOhjMOzr3gthRoRERFX8cQTsGEDBAebA4T/auwshaNQIyIi4go+/BCmTTOXP/kEWrSwth43pFAjIiJitW3b4OIM+RMnwoABVlbjthRqRERErHT8OAwaBJmZ5kR7EyZYXZHbUqgRERGxyvnzZpBJTISWLeHjj8HXvX41G4bBLyd/4bUtrxGzOMbSWjSkWkRExAqGYd5y+u47c0Dw0qVQvrzVVRVKZnYmmxM2s/zX5azYt4L9f+y3r5twwwTCq4RbUpdCjYiIiBWmTfv7ysyCBeYj3C7sZPpJVu1bxfK9y1lzYA0pGSn2dTY/Gz3q9yCqSRRVylaxrEaFGhERkdK2bh3861/m8uuvQ69e1taTD8Mw2J28m+V7l7Ni7wq2Ht1KjpFjX18tqBr9mvQjKjyKmxveTPkA668yKdSIiIiUpgMHzAn2srPNVgiPPWZ1RXYZWRl8c/gbe5A5eOZgrvXXVb+OqPAoosOj6VC7A74+rjX+R6FGRESktKSmmo9rnz5tNqh8913w8bG0pKS0JFbuW8mKvStYc2ANqZmp9nUBfgHc1OAmosOj6Rfej3oV6llY6dUp1IiIiJSGnByzMeXPP0ONGrB4MQQGlnoZhmHwU9JP9kG+249ux8Cwr68RXIOoJlFEhUfRq2EvgmxBpV5jUSnUiIiIlIZJk8wgY7PBokVQq1ap7fp81nk2HNzAir0rWLFvBQlnE3Ktb1uzLdHh0USFR9G2ZluXu61UWAo1IiIiJW3JEnjuOXP53XchIqLEd5l4LpGV+1ayfO9yYn+LJf1Cun1dYJlAejXsZd5WatKP2iG1S7ye0qBQIyIiUpJ27YKYvyale+QRuPvuEtmNYRjEn4i3D/L93/H/5Vpfu3xtosLN20o3NbiJcv7lSqQOKynUiIiIlJQ//oD+/c0BwjfeaD6+7UTpF9JZf3C9eVtp7wqOnTuWa32HWh3st5Va12iNj8WDkkuaQo2IiEhJyMqC4cPNR7jr14fPPgN//2J/7LGUY/axMV/99hV/Zv1pX1fOvxyRjSKJahJFv/B+1AiuUez9uROFGhERkZLw739DbCyUK2e2QKhatUgfk2PkEHc8jhV7V7B873J2ntiZa33dkLpEh0cT3TSaHvV7EFim9J+ochUKNSIiIs72ySfwxhvm8scfw7XXOvT2tMw01v22juV7l/Plvi85kXrCvs4HHzrW6Wi/rdSqWiuPv61UWAo1IiIizvS//8E//mEuP/MM3HZbod6WcDbBPjZm/cH1ZGRn2NcF24Lp3ag3UeFR9G3Sl2pB1UqicrenUCMiIuIsiYnmjMEZGRAdDc8/X+CmOUYO3x37zn5b6cfff8y1vn7F+uZtpfBobgi7gYAyASVcvPtTqBEREXGGjAwYPBiOH4dmzeDTT80O3Jc4l3GO2N9iWb53OSv3rSQpLcm+ztfHl4g6EfbbSs1Dm+u2koMUakRERIrLMOChh2DrVqhY0RwYHBICwKEzh+wtCTYe2khmdqb9bSEBIdzS+BaimkTRp0kfqpYr2mBiMSnUiIiIFNeMGfDBB+DrS/a8OWwLSGLFuv+yfO9ydiXvyrVpo0qN7E8rda3XFZufzaKiPY9CjYiISHFs3MjZpx5lTQtYMaI1K3+8k1PbT9lX+/n40bVeV6LCo4gOjya8SrhuK5UQhRoREZEi2P/HflZsm83yRZP55l85ZPkBWd9DFlQMrEifxn2IDo+md+PeVC5b2epyvYJCjYiISCFk5WSx5cgW+/iYX07+Yq6oa/6jaeVwopveSlR4FF3qdaGMr37Fljb9GxcRESnA6T9Ps3r/albsW8Gqfas4ff60fV0Zw4cbDhpEHQ8m6s0vadLyBgsrFVCoERERyeXXk7/a547ZnLCZbCPbvq5y2cr0bdKX6F1ZRL40n4rZ/rB+FbTsamHFcpFCjYiIeLUL2RfYnLCZ5XuXs2LvCvb9sS/X+uahze1zx0TUicBv5Sp49lYwgFnvQFcFGlehUCMiIl7nVPopVu1fxYq9K1i9fzVnM87a1/n7+tOjfg+iwqOICo+iYaWGf79xzx4YOdKcl+aBB/5uhyAuQaFGREQ8nmEY7Dm5x35bacuRLeQYOfb1VctVpV+TfkSHR3Nzo5sJCQjJ+yFnzkD//nDuHNxwA0ydWmr1S+Eo1IiIiEfKzM7k60Nfm00i963gt9O/5Vp/bfVriWoSRXTTaDrU6oCfr1/BH5adDSNGwL59UK8efP452DRpnqtRqBEREY+RnJbMyn0rWb53OWsPrOVc5jn7OpufjZsa3ER0eDT9mvQjrGJY4T94/HhYvRrKloUlS6CaumS7IoUaERFxW4Zh8HPSz/ZBvtuObsPAsK+vHlTdPjamV8NeBNuCHd/JvHkwZYq5/N//Qps2TqpenE2hRkRE3Mr5rPNsPLTRvK20dwWHzx7Otb5NjTb2lgTtarXD18e3gE8qhLg4uOcec/npp2H48GJULiVNoUZERFzeidQT9ttKsQdiSbuQZl8XWCaQng16mreVwvtRJ6SOc3aalAQDB8L589C3L0ya5JzPlRKjUCMiIi7HMAx++P0He0uC7459l2t9rfK1iGpi3lbq2bAn5fzLObeAzEy47TY4cgTCw2HuXPC7wkBicQkKNSIi4hL+vPAn6w+utz+tdDTlaK717Wu1tz+t1KZGm5LtdP3YY7BpE4SEwNKlUKFCye1LnEahRkRELHP83HG+3Psly/cuZ91v6/gz60/7urJlynJzo5uJDo+mb5O+1Cpfq3SKevdd88fHx7xCc801pbNfKTaFGhERKTU5Rg7fJ35vH+QblxiXa33dkLr2p5VurH8jZf3Llm6BmzbBI4+Yyy+/DP36le7+pVgUakREpESlZabx1cGvWP7rcr7c9yWJqYn2dT74cH3t6+29la6tfm3J3la6koQEGDwYsrJg2DD497+tqUOKTKFGRESc7sjZI/axMesPrud81nn7umBbMJGNIolqEkXfJn2pHlzdwkr/kp5uPumUnAytW8MHH5i3n8StKNSIiEix5Rg5/O/Y/+y9lX74/Ydc68MqhBEdHk1002i6h3UnoEyARZXmwzDgvvvg+++halVzxuCgIKurkiJQqBERkSJJzUwl9kAsy/eat5WS0pLs63zwIaJuhP22UovQFtbdVrqaV181Zw0uUwa++ALCHGifIC5FoUZERArt0JlD9kG+Gw5tIDM7076uvK08tzS+hahw87ZS1XJVLay0kFavNmcKBnjrLeje3dp6pFgUakREpEDZOdlsP7bdflvp56Sfc61vWKmheVspPJpuYd2w+blR5+q9e822B4YB//gHPPCA1RVJMSnUiIhILikZKaw9sJble5ezct9KTqaftK/z9fGlS90u9ttK11S9xnVvK13J2bPQv7/5zy5dYPp0DQz2AAo1IiLCb6d/s7ck+PrQ11zIuWBfVyGgAn2a9CGqSRR9mvShctnKFlbqBDk5cMcd8MsvUKcOLFwINje6wiQFUqgREfFCWTlZbD2yleV7l7Ni7wr2nNyTa314lXD71Zgudbvg7+dvUaUl4NlnYcUKCAyExYuhugs8Ui5OoVAjIuIlzpw/w+r9q1mxdwWr9q/ijz//sK/z8/HjhrAb7LP5hlcJt7DSEvTZZ/DSS+by++9D+/bW1iNOpVAjIuLB9p7aax/ku+nwJrKNbPu6SoGV6NukL9Hh0fRu3JuKgRWtK7Q0/PAD3H23ufzEE+YtKPEoCjUiIh7kQvYFvj3yrX18zN5Te3Otb1a1mf22UkTdCMr4esmvgZMnzYHB6ekQGQmvvGJ1RVICvORvs4iI5/rjzz9YtW8VK/atYPX+1Zw5f8a+zt/Xn+71uxPVxLyt1KhyI+sKtcqFCzBkCBw+DI0bw/z54OdndVVSAhRqRETcjGEY/HLyF/sg32+PfEuOkWNfX7VcVfttpchGkYQEhFhYrQsYOxY2boTgYFi6FCpVsroiKSEKNSIibiAzO5NvDn9jHx/z2+nfcq1vWa2l/bZSx9od8fPVlQjAbEw5fbq5PGcONG9ubT1SohRqRERcVHJaMqv2r2L53uWs2b+Gc5nn7OtsfjZurH+j/Wml+hXrW1eoq9qy5e9Zgl94AW691dp6pMQp1IiIuAjDMNiVvMs+yHfrka0YGPb11YKq2cfG9GrYi/IB5S2s1sUdPQqDBpnjaQYPhvHjra5ISoFCjYiIhTKyMth4aKPZJHLfCg6dOZRrfesarYlqEkV002ja12qPr4+vNYW6kz//hIED4fffoVUr+Ogj8NW/N2+gUCMiUsp+T/2dlftWsnzvctYeWEvahTT7ugC/AHo27El0eDT9mvSjboW6FlbqhgwD7r8fduyAypXNgcHBwVZXJaVEoUZEpIQZhsGPv/9of1rpu2Pf5bqtVDO4pn1sTM8GPQmyBVlYrZubOhU++cR8ZPvzz6FBA6srklKkUCMiUgLOZ51n/cH15m2lvSs4knIk1/p2NdsRFR5FdHg0bWq20W0lZ4iNNWcKBnjjDbjpJmvrkVJXpLNoxowZNGjQgMDAQNq1a8emTZsK3DYxMZGRI0fStGlTfH19GTNmTJ5tdu3axeDBg6lfvz4+Pj5MnTo1zzYTJ07Ex8cn10+NGjWKUr6ISIlIPJfI+3Hv039+f6r8XxX6ze3HzB0zOZJyhLJlyhIdHs2sqFkcG3uMHf/cwcQeE2lXq50CjTPs3w/DhpkduO++Gx55xOqKxAIOX6lZsGABY8aMYcaMGXTp0oX33nuPPn36sHv3burVq5dn+4yMDEJDQxk/fjxvvvlmvp+Znp5Ow4YNGTJkCI8//niB+27RogXr1q2z/9lPM0KKiIUMw+D7xO/tc8fEJcblWl8npI79aaWbGtxEWf+yFlXq4c6dM1sgnD4NnTrBzJng42N1VWIBh0PNG2+8wb333st9990HwNSpU1mzZg0zZ85k8uTJebavX78+b731FgD//e9/8/3MDh060KFDBwCefvrpgostU0ZXZ0TEUukX0vnqt69Yvnc5X+77kuPnjudaf33t6+1PK11X/Tp89Mu1ZOXkwJ13wu7dULMmLFwIAQFWVyUWcSjUZGZmEhcXlyd4REZGsmXLFqcWlp99+/ZRq1YtAgIC6NixIy+//DINGzYscPuMjAwyMjLsf05JSSnxGkXE8xxNOWofG/PVwa84n3Xevi7IP4jIRpFEhUfRt0lfagTrf7xK1QsvwJIlYLPB4sVQq5bVFYmFHAo1J0+eJDs7m+rVq+d6vXr16pw4ccKphV2uY8eOzJ49m/DwcH7//XcmTZpE586d2bVrF1WqVMn3PZMnT+b5558v0bpExPPkGDnsOL7Dflsp/kR8rvX1KtQjOjya6PBoutfvTmCZQGsK9XaLFsHF/8bPmgUdO1pbj1iuSE8/XX451TCMEr/E2qdPH/tyq1atiIiIoFGjRnz88ceMHTs23/eMGzcu17qUlBTq1tWcDyKSV2pmKut+W8fyX83bSr+n/W5f54MPnep0svdWalmtpW4rWe2nn8zbTgBjxsCoUZaWI67BoVBTtWpV/Pz88lyVSUpKynP1pqQFBQXRqlUr9u3bV+A2AQEBBOjeqogU4PCZw/aZfDcc3EBG9t+3q8vbytO7cW+impi3lUKDQi2sVHI5dcocGJyWBj17wquvWl2RuAiHQo3NZqNdu3bExsYycOBA++uxsbH079/f6cVdSUZGBnv27KFbt26lul8RcV/ZOdl8d+w7+22ln5J+yrW+QcUG5m2lptHcEHYDNj+bRZVKgbKyzEe3Dx40J9ZbsADKaMo1MTn8N2Hs2LHExMTQvn17IiIimDVrFgkJCYwePRowb/kcO3aM2bNn298THx8PQGpqKsnJycTHx2Oz2Wj+Vwv4zMxMdu/ebV8+duwY8fHxBAcH07hxYwCeeOIJoqOjqVevHklJSUyaNImUlBRG6ZKjiFxBSkYKsQdiWb53OSv3rSQ5Pdm+ztfHly51u9hn821WtZluK7m6J5+Er76CoCCzBUIBYyrFOzkcaoYNG8apU6d44YUXSExMpGXLlqxcuZKwsDDAnGwvISEh13vatGljX46Li2Pu3LmEhYVx6NAhAI4fP55rm9dee43XXnuN7t27s3HjRgCOHj3KiBEjOHnyJKGhoXTq1Ilt27bZ9ysictFvp3+zX435+tDXXMi5YF9XIaACtzS+hajwKPo07kOVcvql6DY+/thsgwAwe7bZrFLkEj6GYRhX38wzpKSkUKFCBc6ePUtISIjV5YiIkxiGwbaj21jyyxJW7FvB7uTdudY3rtzY/rRS13pd8ffzt6hSKbLt26F7d8jIgGef/fupJ/EKhf39rRuRIuLWsnOyeXTVo8zYMcP+mp+PH13rdbU/rdS0alMLK5RiO34cBg40A03//vDcc1ZXJC5KoUZE3FZGVgZ3LrmTz3Z9hg8+DGs5jFvDb+WWxrdQqWwlq8sTZ8jIgMGDITERWrQwO3D7qleW5E+hRkTcUmpmKgMXDGTdb+vw9/Xnk4GfMKzlMKvLEmcyDHjgAdi2DSpWNGcOLl/e6qrEhSnUiIjbOZl+kr5z+vK/4/8jyD+IRcMWEdko0uqyxNmmT4cPPzSvzCxYAH89DStSEIUaEXErCWcTiPwkkl9P/UqVslVYeftKrq99vdVlibOtXw+PP24uv/oqRCq0ytUp1IiI29iTvIfITyM5mnKUOiF1WHvHWpqFNrO6LHG2gwdhyBDIzoaYmL/DjchVKNSIiFvYfnQ7fef25Y8//+Caqtew9o611K2gXm4eJzUVBgyAP/6A9u3hvfdAEyJKIWkIuYi4vLUH1tJzdk/++PMPrq99PZvv3qxA44kMA+66C378EapXh8WLoWxZq6sSN6JQIyIubf7P84maG0XahTQiG0Xy1Z1faRZgT/XSS7BwIfj7w6JFUKeO1RWJm1GoERGX9c537zBy4Ugu5FxgWIthLB+xnGBbsNVlSUlYtgwmTDCXZ86Ezp2trUfckkKNiLgcwzCYuHEiD696GAODhzo8xNzBc9U121Pt3g133GEuP/QQ3HuvtfWI29JAYRFxKZe3PZjYfSLPdn9W3bM91enTZuuDc+fM3k5vvml1ReLGFGpExGVc3vZget/pPNjhQavLkpKSlQXDh8P+/RAWBp9/bo6nESkihRoRcQlqe+CFxo2DtWuhXDmzBUJoqNUViZtTqBERy13e9mDxsMXc3Ohmq8uSkjRnDrz2mrn84YfQurWl5YhnUKgREUup7YEX2rED7rvPXP7Pf2DoUGvrEY+hUCMilrm07UHdkLqsuWON2h54uhMnYOBAOH8eoqLgxRetrkg8iEKNiFji0rYHzao2Y80dazRLsKfLzITbboOjR+Gaa+DTT80O3CJOolAjIqVuzf41DPpsEOkX0rm+9vWsHLlSswR7OsOAhx+Gb7+FChVg6VLznyJOpIgsIqVq/s/ziZ4XTfqFdLU98Cbvvgvvv282p5w3D8LDra5IPJBCjYiUGrU98FLffAOPPmouv/IK9OljbT3isRRqRKTEGYbBcxueU9sDb3T4sDmOJisLRoyAJ5+0uiLxYBpTIyIlKjsnm0dWPcLMHTMBtT3wKunpMGAAJCdDmzbw//6feftJpIQo1IhIiVHbAy9mGHDPPRAfb84UvGSJOXOwSAlSqBGREnF524NPB33K0BaaZM1rTJkCCxZAmTKwcCHUq2d1ReIFFGpExOnU9sDLrVxpzhQM8Pbb0K2btfWI11CoERGnUtsDL/frr+aAYMOA+++H0aOtrki8iEKNiDjN5W0P1sas5Zqq11hdlpSWM2fg1lshJQW6doVp06yuSLyMQo2IOIXaHni57Gy4/XbYuxfq1oUvvgCbHtmX0qVQIyLFprYHwoQJ5liawEBYvBiqV7e6IvFCmnxPRIpFbQ+EBQtg8mRz+YMPoF07a+sRr6VQIyJFNv276fa2B8NbDlfbA2+0cyfcfbe5/NRTMHKktfWIV1OoERGHXWx78MiqR+xtD+YMmqO2B94mKcmcMfjPP+GWW+Dll62uSLycxtSIiEMub3vwfI/nmXDDBLU98DYXLsCQIZCQAE2amJ23/fysrkq8nEKNiBTa5W0P3un7Dg90eMDqssQKY8aY3bfLl4elS6FiRasrElGoEZHCOZdxjkGfDVLbA4FZs2DGDLM55Zw50KyZ1RWJAAo1IlIIansgdt9+Cw8/bC5PmgTR0dbWI3IJhRoRuaLL2x6sun0VHWp3sLosscKRIzB48N/jacaNs7oikVwUakSkQLuTd9P7095qeyDmE04DB8Lvv8O118KHH5q3n0RciEKNiORr29Ft9JvbT20PxGxO+Y9/QFwcVKliDgwOCrK6KpE8FGpEJI9L2x50rN2RL0d+qVmCvdnrr5sDgv38zJ5O9etbXZFIvjT5nojkcnnbg3V3rlOg8WZr1sC//20uT50KPXpYWY3IFSnUiIid2h5ILvv2wfDhkJMD994LDz1kdUUiV6RQIyJ52h483OFhtT3wdikp0L8/nDkDERHwzjsaGCwuT2NqRLyc2h5IHjk5EBMDe/ZArVqwcCEEBFhdlchVKdSIeDG1PZB8TZwIy5aZQWbxYqhZ0+qKRApFoUbES6ntgeTriy/gxRfN5Vmz4Prrra1HxAEKNSJe6PK2B0uGL6FXw15WlyVW+/FHGDXKXB47Fu6809p6RBykUCPiZdT2QPJ18qQ5MDg9HW6+GaZMsboiEYcp1Ih4kd3Ju4n8JJJj546p7YH87cIFGDoUDh2Chg1h/nwoo18P4n70t1bES6jtgRToiSdgwwYIDjYHCFeubHVFIkWiUCPiBdT2QAr04YcwbZq5/Mkn0KKFtfWIFIMm3xPxcPN+mqe2B5K/bdtg9GhzeeJEGDDAympEik2hRsSDTf9uOrcvul1tDySv48dh0CDIzISBA2HCBKsrEik2hRoRD6S2B3JF58+bQSYxEVq2hI8/Bl/9OhD3pzE1Ih5GbQ/kigzDvOX03XfmgOClS6F8eaurEnEKhRoRD5KRlUHM4hg+3/252h5I/qZN+/vKzIIF5iPcIh5CoUbEQ6jtgVzVunXwr3+Zy6+/Dr00i7R4FoUaEQ+gtgdyVQcOmBPsZWebrRAee8zqikScTqFGxM2p7YFcVWqq+bj26dNmg8p33wWNsRIPpFAj4sbU9kCuKifHbEz5889QowYsWgSBgVZXJVIiFGpE3NTlbQ/WxqylTkgdq8sSVzNpEixeDDabGWhq17a6IpESo4kJRNzQmv1r6Dm7J3/8+Qcda3dk092bFGgkryVL4LnnzOV334WICEvLESlpCjUibmbeT/OImhdF+oV0ejfqrbYHkr9duyAmxlx+5BG4+25r6xEpBQo1Im7kYtuDrJwsRrQcwbIRy9T2QPL64w/o398cIHzjjebj2yJeQKFGxA3k1/bg00Gfqu2B5JWVBcOHm49w168Pn30G/v5WVyVSKooUambMmEGDBg0IDAykXbt2bNq0qcBtExMTGTlyJE2bNsXX15cxY8bk2WbXrl0MHjyY+vXr4+Pjw9SpU4u9XxFPkZ2TzUMrH+KFb14AzLYH0/pMw9dH/08i+fj3vyE2FsqVM1sgVK1qdUUipcbh/youWLCAMWPGMH78eHbu3Em3bt3o06cPCQkJ+W6fkZFBaGgo48eP57rrrst3m/T0dBo2bMgrr7xCjRo1nLJfEU+QkZXBiIUjmLljJj74MKPvDJ7t/qz6OEn+PvkE3njDXP74Y7j2WmvrESllPoZhGI68oWPHjrRt25aZM2faX2vWrBkDBgxg8uTJV3xvjx49aN26dYFXYgDq16/PmDFj8lzRKc5+L0pJSaFChQqcPXuWkJCQQr1HxCpqeyAO+d//oFs3yMiAZ56BF1+0uiIRpyns72+HrtRkZmYSFxdHZGRkrtcjIyPZsmVL0Sotwf1mZGSQkpKS60fEHSSnJdNzdk/W/baOIP8gVt6+UoFGCpaYaM4YnJEB0dHw/PNWVyRiCYdCzcmTJ8nOzqZ69eq5Xq9evTonTpxwamHO2O/kyZOpUKGC/adu3bolVqOIsyScTaDbh9343/H/UaVsFTaM2qA+TlKwjAwYPBiOH4dmzeDTT80O3CJeqEh/8y+/n28YRqnc43d0v+PGjePs2bP2nyNHjpR0iSLFsjt5N50/6Myvp36lbkhdNt+zWX2cpGCGAQ89BFu3QsWK5sBg3VoXL+ZQm4SqVavi5+eX5+pIUlJSnqsozlTU/QYEBBAQEFBidYk4k9oeiMNmzIAPPjCvzMyfD02aWF2RiKUculJjs9lo164dsbGxuV6PjY2lc+fOTi3MFfYrUlpW71+ttgfimI0b4bHHzOUpU6B3b0vLEXEFDje0HDt2LDExMbRv356IiAhmzZpFQkICo0ePBsxbPseOHWP27Nn298THxwOQmppKcnIy8fHx2Gw2mjdvDpgDgXfv3m1fPnbsGPHx8QQHB9O4ceNC7VfEXc37aR53LrmTrJwsejfqzcKhCwmyBVldlriyQ4fgttsgOxtuvx3+9S+rKxJxDUYRvPPOO0ZYWJhhs9mMtm3bGl9//bV93ahRo4zu3bvn2h7I8xMWFmZff/DgwXy3ufxzrrTfwjh79qwBGGfPnnX0kEVKxNvb3zZ8JvoYTMQY8cUIIyMrw+qSxNWlphrGddcZBhhGu3aGkZ5udUUiJa6wv78dnqfGnWmeGnEVhmEwceNE+yzBD3d4mLf6vKVZguXKDAOGDYPPP4dq1WDHDtBTneIFCvv72+HbTyJSPNk52Ty88mHejXsXgBd6vMAzNzyjWYLl6iZPNgONvz8sXKhAI3IZhRqRUpSRlUHM4hg+3/05PvjwTt93eKDDA1aXJe5gxQpzpmCA6dOha1dr6xFxQQo1IqVEbQ+kyPbsgZEjzdtPDzwA//yn1RWJuCSFGpFSkJyWTN+5fdlxfAdB/kEsGb5EswRL4Zw5A/37w7lzcMMNcIXeeSLeTqFGpIQlnE0g8pNIfj31K1XLVWXlyJWaJVgKJzsbRoyAffugXj1zPI3NZnVVIi5LoUakBO1O3k3kJ5EcO3eMuiF1WRuzlmuqXmN1WeIuxo+H1auhbFlYssR84klECqRQI1JC1PZAimXePHOmYID//hfatLG2HhE3oEkxRErApW0POtXppLYH4pi4OLjnHnP56adh+HBr6xFxEwo1Ik4276d5RM+LJv1COr0b9WZdzDqqlKtidVniLpKSYOBAOH8e+vaFSZOsrkjEbSjUiDjR29vf5vZFt5OVk8WIliNYNmKZ+jhJ4WVmmj2djhyB8HCYOxf8/KyuSsRtKNSIOIFhGDy74VkeXf0oBgYPd3iYTwd9is1PT6qIAx57DDZtgpAQWLoUKlSwuiIRt6KBwiLFpLYH4hTvvmv++PiYV2iu0VNyIo5SqBEpBrU9EKfYtAkeecRcfvll6NfP2npE3JRCjUgRncs4x8AFA/nq4Ff4+/ozZ9AchrQYYnVZ4m4SEmDwYMjKMjtw//vfVlck4rYUakSKQG0PxCnS080nnZKToXVr+OAD8/aTiBSJQo2Ig9T2QJzCMOC+++D776FqVXPG4CA9KSdSHAo1Ig5Q2wNxmldfNWcNLlMGvvgCwsKsrkjE7SnUiBTStqPb6DunL6fPn1bbAyme1avNmYIB3noLune3th4RD6F5akQK4WLbg9PnT6vtgRTP3r1m2wPDgH/8Ax7Q03IizqJQI3IVansgTnP2LPTvb/6zSxeYPl0Dg0WcSKFG5Are3v42IxeNVNsDKb6cHLjjDvjlF6hd2xxHY9OM0yLOpFAjko9L2x4APHL9I2p7IMXz7LOwYgUEBppPOtWoYXVFIh5HA4VFLqO2B+J0n30GL71kLr//PrRvb209Ih5KoUbkEpe3PZjRbwaj24+2uixxZ/HxcPfd5vITT5i3oESkRCjUiPxFbQ/E6ZKTYcAAc+bgyEh45RWrKxLxaAo1IqjtgZSACxdg6FA4fBgaN4b588HPz+qqRDyaQo14vcNnDtP7095qeyDONXYsbNwIwcGwdClUqmR1RSIeT6FGvNqupF30/rQ3x84do16Feqy5Y43aHkjxffCBOQcNwJw50Ly5tfWIeAmFGvFal7Y9aB7anDV3rNEswVJ8W7b8PUvwCy/ArbdaW4+IF9E8NeKVLm978M1d3yjQSPEdPQqDBpnjaQYPhvHjra5IxKso1IjXmfvTXLU9EOf7808YOBB+/x1atYKPPgJf/SdWpDTpjBOv8vb2t7l90e1qeyDOZRhw//2wYwdUrmwODA4OtroqEa+jUCNeQW0PpERNnQqffGI+sv3559CggdUViXglDRQWj3d524MXb3yR8d3Gq+2BOEdsrDlTMMAbb8BNN1lbj4gXU6gRj5aRlcEdi+/gi91fqO2BON/+/TBsmNmB++674ZFHrK5IxKsp1IjHUtsDKVHnzkH//nD6NHTqBDNngq7+iVhKoUY8ktoeSInKyYE774Tdu6FmTVi4EAICrK5KxOsp1IjHOXzmMJGfRrL31F61PZCS8cILsGQJ2GyweDHUqmV1RSKCQo14mMvbHqy9Yy1Nqza1uizxJIsWwfPPm8uzZkHHjtbWIyJ2CjXiMdT2QErcTz+Zt50AHnsMRo2yth4RyUXz1IhHUNsDKXGnTpkDg9PSzMe2X3vN6opE5DIKNeL2Lm17cEvjW9T2QJwvK8t8dPvgQXNivc8+gzK60C3iahRqxK1d3vZg6fClansgzvfkk/DVVxAUZLZAqKLQLOKKFGrELantgZSajz822yAAzJ5tNqsUEZek66fidrJzsnlo5UO8F/ceoLYHUoK2bzcbVQI8+ywMGmRtPSJyRQo14lbU9kBKzfHjMHAgZGSYA4Sfe87qikTkKhRqxG2o7YGUmowMGDwYEhOhRQuzA7ev7taLuDqFGnELyWnJ9JnTh7jEOIJtwSwetlhtD6RkGAY88ABs2wYVK5ozB5cvb3VVIlIICjXi8i5ve7Dq9lW0r9Xe6rLEU02fDh9+aF6ZWbAAGje2uiIRKSSFGnFpansgpWr9enj8cXP51VchMtLaekTEIQo14rK2HtlKv7n91PZASsfBgzBkCGRnQ0zM3+FGRNyGRr6JS1q9fzW9Pullb3uw6e5NCjRSclJTYcAA+OMPaN8e3nsPNEWAiNtRqBGXk1/bg8plK1tdlngqw4C77oIff4Tq1WHxYihb1uqqRKQIFGrEpUzbPk1tD6R0vfQSLFwI/v6waBHU0RVBEXelUCMuwTAMJqyfwGOrHwPU9kBKybJlMGGCuTxzJnTubG09IlIsGigsllPbA7HE7t1wxx3m8kMPwb33WluPiBSbQo1YSm0PxBKnT5utD86dg+7d4c03ra5IRJxAoUYsc2nbA5ufjTmD5nBb89usLks8XVYWDB8O+/dDWBh8/rk5nkZE3J5CjVji8rYHS4YtoWfDnlaXJd5g3DhYu9Z8wmnJEggNtboiEXEShRpnePJJSE+HkBCzR8zV/hkc7NXN8dT2QCwzZw689pq5/NFH0Lq1ldWIiJMp1DjDJ5/A77879p7g4MIFIA8LSGp7IJbZsQPuu89c/s9/YOhQa+sREadTqHGG//wHTp2ClBRz4OGV/pmVZb4nNdX8SUws/v7dJCBd3vZg7R1rqR1Su8T2J2J34gQMHAjnz0NUFLz4otUViUgJUKhxhkcfLdx2hgEZGX+HnKsFIHcMSBeXLwtIq/evZvBng0m/kE6nOp34cuSXmiVYSkdmJtx2Gxw9Ck2bwqefutXVTREpPIWa0uTjA4GB5k+1asX7rIsBqbjBqBQC0txWMKrTCbJ8DW5JqcYX39Qn6PsJVw9GBQQkkUIzDHj4Yfj2W6hQAZYuNf8pIh5JocZdXRqQivv0hjMC0sXlywLStBapPPbXJK0jf4QPlyZhy57veI2OXkEqaJ0Cknd59114/33zfJk3z7xSIyIeq0ihZsaMGbz66qskJibSokULpk6dSrdu3fLdNjExkX/961/ExcWxb98+Hn30UaZOnZpnu4ULFzJhwgQOHDhAo0aNeOmllxg4cKB9/cSJE3n++edzvad69eqcOHGiKIcglyqBgGSkpPDspheY9PM7ADxaLZo3Bw/Dt3fa1YNRAQGp1G+xXW0bBSTX9s03f98afuUV6NPH2npEpMQ5HGoWLFjAmDFjmDFjBl26dOG9996jT58+7N69m3r16uXZPiMjg9DQUMaPH8+bBczauXXrVoYNG8aLL77IwIEDWbx4MUOHDmXz5s107NjRvl2LFi1Yt26d/c9+fn6Oli8lzceHbJs/D333LO/9XMy2B0W5glTQOqsCUmGvLikgOdfhw+Y4mqwsGDHCnHZBRDyej2EYhiNv6NixI23btmXmzJn215o1a8aAAQOYPHnyFd/bo0cPWrdunedKzbBhw0hJSWHVqlX212655RYqVarEvHnzAPNKzZIlS4iPj3ek3FxSUlKoUKECZ8+eJSQkpMifIwW7vO3BzH4zub/9/VaX5VhAuto2lwYkZyooIDk6YNvbA1J6OnTpAvHx0KYNbN4M5cpZXZWIFENhf387dKUmMzOTuLg4nn766VyvR0ZGsmXLlqJVinml5vHHH8/1Wu/evfOEn3379lGrVi0CAgLo2LEjL7/8Mg0bNizwczMyMsjIyLD/OSUlpcg1ytWdyzjHgAUDWH9wveu1PSjtMUiFvbpU2leQPD0gGQbcc48ZaEJDzRmDFWhEvIZDoebkyZNkZ2dTvXr1XK8Xd2zLiRMnrvqZHTt2ZPbs2YSHh/P7778zadIkOnfuzK5du6hSpUq+nzt58uQ843CkZHhV24PSCkiODtgurYBU1Ef+SyMgTZkCCxZAmTKwcCHkc0tcRDxXkQYKXz42wjAMx8dLOPiZfS4Z5NeqVSsiIiJo1KgRH3/8MWPHjs33M8eNG5drXUpKCnXr1i1WnZKX2h4UQ0kFJGc86n/hgvm5JRGQijtZZH4BaeVKcyJMgLffhgIeXhARz+VQqKlatSp+fn55rsokJSXludLiiBo1ajj8mUFBQbRq1Yp9+/YVuE1AQAABAQFFrkuublfSLiI/jeT4uePUq1CP2JhYwquEW12Wd3JmQILcE0W6YkAKCsoddH75xQx2998Po0cX//NFxO04FGpsNhvt2rUjNjY21+PWsbGx9O/fv8hFREREEBsbm2tczdq1a+ncuXOB78nIyGDPnj0FPkouJU9tDzxcQIAZjlwlIF1cvhiQ0tLMn0sDUteuMG1a8esVEbfk8O2nsWPHEhMTQ/v27YmIiGDWrFkkJCQw+q//Mxo3bhzHjh1j9uzZ9vdcfGIpNTWV5ORk4uPjsdlsNG/eHIDHHnuMG264gSlTptC/f3+WLl3KunXr2Lx5s/0znnjiCaKjo6lXrx5JSUlMmjSJlJQURo0aVZzjlyJS2wNxSGkEpIwMuPlmsNmKvw8RcUsOh5phw4Zx6tQpXnjhBRITE2nZsiUrV64kLCwMMCfbS0hIyPWeNm3a2Jfj4uKYO3cuYWFhHDp0CIDOnTszf/58nnnmGSZMmECjRo1YsGBBrjlqjh49yogRIzh58iShoaF06tSJbdu22fcrpWfuT3MZtWQUWTlZ3NL4Fr4Y8gVBtiCryxJv4cyAJCIexeF5atyZ5qkpvmnbp/HY6scAGNlqJB/1/wh/P3+LqxIREU9W2N/fbjQBhVjJMAwmrJ9gDzSPXv8onwz8RIFGRERchhpaylVl52Tz0MqHeC/ObHsw6cZJ/Kfbf4r9GL+IiIgzKdTIFbls2wMREZHLKNRIgVy67YGIiMhlFGokX17V9kBERDyCQo3kobYHIiLijhRqJBe1PRAREXelUCN2ansgIiLuTPPUCACr9q2i1ye9OH3+NBF1Ith09yYFGhERcSsKNcKcH+dw6/xbSb+QTp/GfYiNiVUfJxERcTsKNV5u2vZp3LH4DrJyshjZaiRLhy9VHycREXFLCjVeSm0PRETE02igsBdS2wMREfFECjVeRm0PRETEUynUeBG1PRAREU+mUOMl1PZAREQ8nUKNF1DbAxER8QYKNR5ObQ9ERMRbKNR4sEvbHrQIbcGaO9ZolmAREfFYmqfGQ63at4qes3va2x58c/c3CjQiIuLRFGo80MW2B39m/am2ByIi4jUUajzMpW0Pbm91u9oeiIiI11Co8RCXtz14rONjzB44W20PRETEa2igsAdQ2wMRERGFGrentgciIiImhRo3prYHIiIif1OocVNJaUn0ndPX3vZg6fCl3NTgJqvLEhERsYxCjRtS2wMREZG8FGrczKVtD8IqhLE2Zq3aHoiIiKBQ41a2HNlC1NwotT0QERHJh+apcROr9q2i1+xeansgIiJSAIUaN6C2ByIiIlenUOPi1PZARESkcBRqXJRhGDyz/hm1PRARESkkDRR2QWp7ICIi4jiFGheTkZXB7YtuZ+Gehfj6+DKz30z+2e6fVpclIiLi8hRqXMjlbQ/mDprL4OaDrS5LRETELSjUuAi1PRARESkehRoXcGnbg9Byoay6fRXtarWzuiwRERG3olBjMbU9EBERcQ6FGgup7YGIiIjzaJ4ai6jtgYiIiHMp1Fjg8rYH6+5cp7YHIiIixaRQU8re2vZWnrYH5fzLWV2WiIiI21OoKSUX2x6MWTMGUNsDERERZ9NA4VKQnZPNg18+yKzvZwHw0k0vMa7rOLU9EBERcSKFmhKmtgciIiKlQ6GmBKntgYiISOlRqCkhansgIiJSuhRqSsChM4fo/WlvtT0QEREpRQo1TvZz0s/0/rS32h6IiIiUMoUaJ1LbAxEREetonhonUdsDERERaynUOIHaHoiIiFhPoaaYjqYc5Z5l96jtgYiIiMU0pqaY6oTU4eMBH7P96HZe7/06vj7KiSIiIlbwMQzDsLqI0pKSkkKFChU4e/YsISEhVpcjIiIihVDY39+6rCAiIiIeQaFGREREPIJCjYiIiHgEhRoRERHxCAo1IiIi4hEUakRERMQjKNSIiIiIR1CoEREREY+gUCMiIiIeoUihZsaMGTRo0IDAwEDatWvHpk2bCtw2MTGRkSNH0rRpU3x9fRkzZky+2y1cuJDmzZsTEBBA8+bNWbx4cbH2KyIiIt7F4VCzYMECxowZw/jx49m5cyfdunWjT58+JCQk5Lt9RkYGoaGhjB8/nuuuuy7fbbZu3cqwYcOIiYnhhx9+ICYmhqFDh7J9+/Yi71dERES8i8O9nzp27Ejbtm2ZOXOm/bVmzZoxYMAAJk+efMX39ujRg9atWzN16tRcrw8bNoyUlBRWrVplf+2WW26hUqVKzJs3r9j7vUi9n0RERNxPifR+yszMJC4ujsjIyFyvR0ZGsmXLlqJVinml5vLP7N27t/0zi7rfjIwMUlJScv2IiIiIZyrjyMYnT54kOzub6tWr53q9evXqnDhxoshFnDhx4oqfWdT9Tp48meeffz7P6wo3IiIi7uPi7+2r3VxyKNRc5OPjk+vPhmHkea0kPtPR/Y4bN46xY8fa/3zs2DGaN29O3bp1i1WriIiIlL5z585RoUKFAtc7FGqqVq2Kn59fnqsjSUlJea6iOKJGjRpX/Myi7jcgIICAgAD7n4ODgzly5Ajly5cvdgi7VEpKCnXr1uXIkSMeO1bH049Rx+f+PP0YdXzuz9OPsSSPzzAMzp07R61ata64nUOhxmaz0a5dO2JjYxk4cKD99djYWPr371+0SoGIiAhiY2N5/PHH7a+tXbuWzp07O3W/vr6+1KlTp8h1Xk1ISIhH/kW9lKcfo47P/Xn6Mer43J+nH2NJHd+VrtBc5PDtp7FjxxITE0P79u2JiIhg1qxZJCQkMHr0aMC85XPs2DFmz55tf098fDwAqampJCcnEx8fj81mo3nz5gA89thj3HDDDUyZMoX+/fuzdOlS1q1bx+bNmwu9XxEREfFuDoeaYcOGcerUKV544QUSExNp2bIlK1euJCwsDDAn27t87pg2bdrYl+Pi4pg7dy5hYWEcOnQIgM6dOzN//nyeeeYZJkyYQKNGjViwYAEdO3Ys9H5FRETEuxVpoPCDDz7Igw8+mO+6jz76KM9rhZkK57bbbuO2224r8n6tFBAQwHPPPZdr/I6n8fRj1PG5P08/Rh2f+/P0Y3SF43N48j0RERERV6SGliIiIuIRFGpERETEIyjUiIiIiEdQqBERERGPoFBTgBkzZtCgQQMCAwNp164dmzZtuuL2X3/9Ne3atSMwMJCGDRvy7rvv5tlm4cKFNG/enICAAJo3b87ixYtLqvyrcuT4Fi1axM0330xoaCghISFERESwZs2aXNt89NFH+Pj45Pk5f/58SR9Kvhw5vo0bN+Zb+y+//JJrO1f6/sCxY7zrrrvyPcYWLVrYt3Gl7/Cbb74hOjqaWrVq4ePjw5IlS676Hnc6Bx09Pnc7Bx09Pnc8Bx09Rnc7BydPnkyHDh0oX7481apVY8CAAfz6669XfZ/V56FCTT4WLFjAmDFjGD9+PDt37qRbt2706dMnz/w7Fx08eJC+ffvSrVs3du7cyX/+8x8effRRFi5caN9m69atDBs2jJiYGH744QdiYmIYOnQo27dvL63DsnP0+L755htuvvlmVq5cSVxcHDfeeCPR0dHs3Lkz13YhISEkJibm+gkMDCyNQ8rF0eO76Ndff81Ve5MmTezrXOn7A8eP8a233sp1bEeOHKFy5coMGTIk13au8h2mpaVx3XXXMX369EJt727noKPH527noKPHd5E7nYOOHqO7nYNff/01Dz30ENu2bSM2NpasrCwiIyNJS0sr8D0ucR4aksf1119vjB49Otdr11xzjfH000/nu/1TTz1lXHPNNbleu//++41OnTrZ/zx06FDjlltuybVN7969jeHDhzup6sJz9Pjy07x5c+P555+3//nDDz80KlSo4KwSi8XR49uwYYMBGKdPny7wM13p+zOM4n+HixcvNnx8fIxDhw7ZX3Ol7/BSgLF48eIrbuNu5+ClCnN8+XHlc/BShTk+dzwHL1WU79CdzkHDMIykpCQDML7++usCt3GF81BXai6TmZlJXFwckZGRuV6PjIxky5Yt+b5n69atebbv3bs3O3bs4MKFC1fcpqDPLClFOb7L5eTkcO7cOSpXrpzr9dTUVMLCwqhTpw5RUVF5/i+yNBTn+Nq0aUPNmjXp2bMnGzZsyLXOVb4/cM53+MEHH9CrV688M3K7wndYFO50DjqDK5+DxeEu56AzuNs5ePbsWYA8f+cu5QrnoULNZU6ePEl2dnae7t/Vq1fP0yX8ohMnTuS7fVZWFidPnrziNgV9ZkkpyvFd7vXXXyctLY2hQ4faX7vmmmv46KOPWLZsGfPmzSMwMJAuXbqwb98+p9Z/NUU5vpo1azJr1iwWLlzIokWLaNq0KT179uSbb76xb+Mq3x8U/ztMTExk1apV3Hfffbled5XvsCjc6Rx0Blc+B4vC3c7B4nK3c9AwDMaOHUvXrl1p2bJlgdu5wnlYpDYJ3sDHxyfXnw3DyPPa1ba//HVHP7MkFbWWefPmMXHiRJYuXUq1atXsr3fq1IlOnTrZ/9ylSxfatm3L22+/zbRp05xXeCE5cnxNmzaladOm9j9HRERw5MgRXnvtNW644YYifWZpKGo9H330ERUrVmTAgAG5Xne179BR7nYOFpW7nIOOcNdzsKjc7Rx8+OGH+fHHH3M1mS6I1eehrtRcpmrVqvj5+eVJjUlJSXnS5UU1atTId/syZcpQpUqVK25T0GeWlKIc30ULFizg3nvv5bPPPqNXr15X3NbX15cOHTqU+v9hFOf4LtWpU6dctbvK9wfFO0bDMPjvf/9LTEwMNpvtitta9R0WhTudg8XhDuegs7jyOVgc7nYOPvLIIyxbtowNGzZQp06dK27rCuehQs1lbDYb7dq1IzY2NtfrsbGxdO7cOd/3RERE5Nl+7dq1tG/fHn9//ytuU9BnlpSiHB+Y/3d41113MXfuXPr163fV/RiGQXx8PDVr1ix2zY4o6vFdbufOnblqd5XvD4p3jF9//TX79+/n3nvvvep+rPoOi8KdzsGicpdz0Flc+RwsDnc5Bw3D4OGHH2bRokWsX7+eBg0aXPU9LnEeOmW4sYeZP3++4e/vb3zwwQfG7t27jTFjxhhBQUH2UepPP/20ERMTY9/+t99+M8qVK2c8/vjjxu7du40PPvjA8Pf3N7744gv7Nt9++63h5+dnvPLKK8aePXuMV155xShTpoyxbds2lz++uXPnGmXKlDHeeecdIzEx0f5z5swZ+zYTJ040Vq9ebRw4cMDYuXOncffddxtlypQxtm/f7vLH9+abbxqLFy829u7da/z888/G008/bQDGwoUL7du40vdnGI4f40V33HGH0bFjx3w/05W+w3Pnzhk7d+40du7caQDGG2+8YezcudM4fPiwYRjufw46enzudg46enzueA46eowXucs5+MADDxgVKlQwNm7cmOvvXHp6un0bVzwPFWoK8M477xhhYWGGzWYz2rZtm+sxtlGjRhndu3fPtf3GjRuNNm3aGDabzahfv74xc+bMPJ/5+eefG02bNjX8/f2Na665JtcJW9ocOb7u3bsbQJ6fUaNG2bcZM2aMUa9ePcNmsxmhoaFGZGSksWXLllI8otwcOb4pU6YYjRo1MgIDA41KlSoZXbt2Nb788ss8n+lK359hOP539MyZM0bZsmWNWbNm5ft5rvQdXnzEt6C/c+5+Djp6fO52Djp6fO54Dhbl76g7nYP5HRtgfPjhh/ZtXPE89PmreBERERG3pjE1IiIi4hEUakRERMQjKNSIiIiIR1CoEREREY+gUCMiIiIeQaFGREREPIJCjYiIiHgEhRoRERHxCAo1IiIi4hEUakRERMQjKNSIiIiIR1CoEREREY/w/wFQJBAka191iwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature, target_vec, test_size=0.2, random_state=128)\n",
    "X_train = X_train / 255.0\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,       # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,   # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,    # randomly flip images\n",
    "    zoom_range=0.2,          # randomly zoom images\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# earlystop = EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=5,\n",
    "#     verbose=1,\n",
    "#     restore_best_weights=True\n",
    "# )\n",
    "h_callback = nn_model.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
    "                                    validation_data=(X_test, y_test),\n",
    "                                    epochs=30)\n",
    "                                    # callbacks=[earlystop])\n",
    "\n",
    "plt.plot(h_callback.history['accuracy'], label='acc', color='red') \n",
    "plt.plot(h_callback.history['val_accuracy'], label='val_acc', color='green') \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b5bfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean session\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae4721-4846-4f62-a93f-115143011191",
   "metadata": {},
   "source": [
    "## 2.3 Model II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e8f65-ed56-4354-b910-2a9ec0bb4813",
   "metadata": {},
   "source": [
    "### 2.3.1 Feature Engineering\n",
    "This step to prove the new features we added has improvement\n",
    "\n",
    "Accuracy from 0.75 to 0.8 by baseline xgboost with only train/test using noisy labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2102a69-3780-4f4c-b64a-d97bdad983e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import skew\n",
    "from scipy.ndimage import sobel\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "NO_BINS = 6\n",
    "# Function for base histogram features\n",
    "def feature_base(imgs, N_TRAIN_IMG = 10000, NO_BINS = 6, BINS = np.linspace(0, 255, NO_BINS)):\n",
    "    feature_mtx = np.empty((N_TRAIN_IMG, 3 * (len(BINS) - 1)))\n",
    "    TARGET_VEC = np.empty(N_TRAIN_IMG)\n",
    "    for i in range(N_TRAIN_IMG):\n",
    "        TARGET_VEC[i] = clean_labels[i]  # Assuming clean_labels is defined elsewhere\n",
    "        \n",
    "        # Histogram features for each channel\n",
    "        feature1 = np.histogram(imgs[i][:, :, 0], bins=BINS)[0]\n",
    "        feature2 = np.histogram(imgs[i][:, :, 1], bins=BINS)[0]\n",
    "        feature3 = np.histogram(imgs[i][:, :, 2], bins=BINS)[0]\n",
    "        \n",
    "        # Concatenate features\n",
    "        feature_mtx[i, ] = np.concatenate((feature1, feature2, feature3), axis=None)\n",
    "    return feature_mtx, TARGET_VEC\n",
    "\n",
    "# Function for advanced features including color statistics and edge detection\n",
    "def feature_adv(imgs, N_TRAIN_IMG = 10000, NO_BINS = 6, BINS = np.linspace(0, 255, NO_BINS)):\n",
    "    noisy_y = np.empty(N_TRAIN_IMG)\n",
    "    feature_mtx = np.empty((N_TRAIN_IMG, 26))\n",
    "    TARGET_VEC = np.empty(N_TRAIN_IMG)\n",
    "    for i in range(N_TRAIN_IMG):\n",
    "        noisy_y[i] = noisy_labels[i]\n",
    "        TARGET_VEC[i] = clean_labels[i]  # Assuming clean_labels is defined elsewhere\n",
    "        \n",
    "        # Existing histogram features\n",
    "        feature1 = np.histogram(imgs[i][:, :, 0], bins=BINS)[0]\n",
    "        feature2 = np.histogram(imgs[i][:, :, 1], bins=BINS)[0]\n",
    "        feature3 = np.histogram(imgs[i][:, :, 2], bins=BINS)[0]\n",
    "        \n",
    "        # Color statistics\n",
    "        color_features = []\n",
    "        for channel in range(3):\n",
    "            channel_data = imgs[i][:, :, channel]\n",
    "            mean = np.mean(channel_data)\n",
    "            std = np.std(channel_data)\n",
    "            skewness = skew(channel_data, axis=None)\n",
    "            color_features.extend([mean, std, skewness])\n",
    "        \n",
    "        # Edge detection feature\n",
    "        sx = sobel(imgs[i][:, :, 0], axis=0, mode='constant')\n",
    "        sy = sobel(imgs[i][:, :, 0], axis=1, mode='constant')\n",
    "        sobel_magnitude = np.sqrt(sx**2 + sy**2).mean()\n",
    "\n",
    "        \n",
    "        # Concatenate all features\n",
    "        feature_mtx[i, ] = np.concatenate((feature1, feature2, feature3, color_features, [sobel_magnitude], [noisy_y[i]]), axis=None)\n",
    "    return feature_mtx, TARGET_VEC\n",
    "\n",
    "# Function to evaluate features with XGBoost\n",
    "def evaluate_feature(feature_mtx, target_vec):\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_mtx, target_vec, test_size=0.2, random_state=128)\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    xgb = XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=500,\n",
    "        objective='multi:softmax', num_class=10)\n",
    "    xgb_m = xgb.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = xgb_m.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66d76a81-3419-473d-9b6f-1df28c25cb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Base Features:\n",
      "Accuracy: 0.3055\n",
      "Evaluating Advanced Features:\n",
      "Accuracy: 0.4605\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "NO_BINS = 6\n",
    "N_TRAIN_IMG = 10000\n",
    "BINS = np.linspace(0, 255, NO_BINS)\n",
    "\n",
    "\n",
    "target_vec = np.empty(N_TRAIN_IMG)  # Initialize target vector\n",
    "\n",
    "# Feature extraction\n",
    "feature_mtx_base, target_vec_base = feature_base(imgs)  # For base features\n",
    "feature_mtx_adv, target_vec_adv = feature_adv(imgs)  # For advanced features\n",
    "\n",
    "# Evaluate features\n",
    "print(\"Evaluating Base Features:\")\n",
    "accuracy_base = evaluate_feature(feature_mtx_base, target_vec_base)\n",
    "print(\"Evaluating Advanced Features:\")\n",
    "accuracy_adv = evaluate_feature(feature_mtx_adv, target_vec_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78991f59-c3f6-4f51-953a-48ffde660d7a",
   "metadata": {},
   "source": [
    "### 2.3.2 Generate 50000 labels better than noisy labels using 10000 labels (noisy and clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b18e11-2080-4fc1-8a39-24b0a61ce121",
   "metadata": {},
   "source": [
    "#### 2.3.2.1 Generate Features\n",
    "Also add noisy label as one of the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b7dfd4a-10cf-470c-933e-90a8caf0235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_img = 10000\n",
    "noisy_y = np.empty(n_train_img)\n",
    "clean_y = np.empty(n_train_img)\n",
    "feature_mtx = np.empty((n_train_img,26))\n",
    "\n",
    "# Generate noisy and clean labels\n",
    "for i in range(n_train_img):\n",
    "\n",
    "    noisy_y[i] = noisy_labels[i]\n",
    "    clean_y[i] = clean_labels[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a197d3-73c7-4463-bbb5-5d3d478f44bc",
   "metadata": {},
   "source": [
    "#### 2.3.2.2 Model Selection\n",
    "\n",
    "XGBoost is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66e4951d-9244-4758-aeaa-9d0a864a137b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.4215\n",
      "XGBoost Accuracy: 0.4515\n",
      "Logistic Regression Accuracy: 0.382\n",
      "KNN Accuracy: 0.3075\n",
      "SVM Accuracy: 0.402\n",
      "Epoch 1/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.2924 - loss: 1.9610\n",
      "Epoch 2/10\n",
      "250/250 - 0s - 464us/step - accuracy: 0.3596 - loss: 1.7944\n",
      "Epoch 3/10\n",
      "250/250 - 0s - 463us/step - accuracy: 0.3791 - loss: 1.7400\n",
      "Epoch 4/10\n",
      "250/250 - 0s - 464us/step - accuracy: 0.3934 - loss: 1.7070\n",
      "Epoch 5/10\n",
      "250/250 - 0s - 463us/step - accuracy: 0.4040 - loss: 1.6820\n",
      "Epoch 6/10\n",
      "250/250 - 0s - 460us/step - accuracy: 0.4104 - loss: 1.6586\n",
      "Epoch 7/10\n",
      "250/250 - 0s - 461us/step - accuracy: 0.4190 - loss: 1.6433\n",
      "Epoch 8/10\n",
      "250/250 - 0s - 462us/step - accuracy: 0.4196 - loss: 1.6280\n",
      "Epoch 9/10\n",
      "250/250 - 0s - 461us/step - accuracy: 0.4245 - loss: 1.6163\n",
      "Epoch 10/10\n",
      "250/250 - 0s - 458us/step - accuracy: 0.4310 - loss: 1.5985\n",
      "Neural Network Accuracy: 0.40049999952316284\n",
      "Epoch 1/10\n",
      "250/250 - 1s - 2ms/step - accuracy: 0.2738 - loss: 1.9976\n",
      "Epoch 2/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3425 - loss: 1.8294\n",
      "Epoch 3/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3631 - loss: 1.7842\n",
      "Epoch 4/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3669 - loss: 1.7625\n",
      "Epoch 5/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3817 - loss: 1.7406\n",
      "Epoch 6/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3853 - loss: 1.7250\n",
      "Epoch 7/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3845 - loss: 1.7143\n",
      "Epoch 8/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3913 - loss: 1.7046\n",
      "Epoch 9/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3965 - loss: 1.6881\n",
      "Epoch 10/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.4075 - loss: 1.6736\n",
      "CNN Accuracy: 0.38749998807907104\n",
      "Epoch 1/10\n",
      "250/250 - 1s - 3ms/step - accuracy: 0.2885 - loss: 1.9582\n",
      "Epoch 2/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.3411 - loss: 1.8395\n",
      "Epoch 3/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.3521 - loss: 1.8094\n",
      "Epoch 4/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.3627 - loss: 1.7902\n",
      "Epoch 5/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.3636 - loss: 1.7731\n",
      "Epoch 6/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.3759 - loss: 1.7624\n",
      "Epoch 7/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.3795 - loss: 1.7540\n",
      "Epoch 8/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.3819 - loss: 1.7396\n",
      "Epoch 9/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.3842 - loss: 1.7312\n",
      "Epoch 10/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.3850 - loss: 1.7189\n",
      "RNN Accuracy: 0.3765000104904175\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.58      0.53       207\n",
      "         1.0       0.46      0.50      0.48       213\n",
      "         2.0       0.37      0.32      0.34       197\n",
      "         3.0       0.37      0.31      0.34       199\n",
      "         4.0       0.47      0.36      0.41       205\n",
      "         5.0       0.28      0.24      0.26       177\n",
      "         6.0       0.36      0.44      0.39       187\n",
      "         7.0       0.40      0.39      0.39       200\n",
      "         8.0       0.53      0.53      0.53       224\n",
      "         9.0       0.42      0.52      0.46       191\n",
      "\n",
      "    accuracy                           0.42      2000\n",
      "   macro avg       0.42      0.42      0.41      2000\n",
      "weighted avg       0.42      0.42      0.42      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.60      0.57       207\n",
      "         1.0       0.54      0.45      0.49       213\n",
      "         2.0       0.39      0.36      0.37       197\n",
      "         3.0       0.43      0.37      0.40       199\n",
      "         4.0       0.49      0.48      0.48       205\n",
      "         5.0       0.31      0.32      0.31       177\n",
      "         6.0       0.40      0.43      0.42       187\n",
      "         7.0       0.43      0.44      0.43       200\n",
      "         8.0       0.53      0.54      0.53       224\n",
      "         9.0       0.44      0.50      0.47       191\n",
      "\n",
      "    accuracy                           0.45      2000\n",
      "   macro avg       0.45      0.45      0.45      2000\n",
      "weighted avg       0.45      0.45      0.45      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.50      0.48       207\n",
      "         1.0       0.40      0.52      0.45       213\n",
      "         2.0       0.29      0.24      0.27       197\n",
      "         3.0       0.31      0.27      0.29       199\n",
      "         4.0       0.42      0.32      0.36       205\n",
      "         5.0       0.26      0.14      0.18       177\n",
      "         6.0       0.34      0.42      0.38       187\n",
      "         7.0       0.41      0.31      0.35       200\n",
      "         8.0       0.46      0.56      0.51       224\n",
      "         9.0       0.37      0.49      0.42       191\n",
      "\n",
      "    accuracy                           0.38      2000\n",
      "   macro avg       0.37      0.38      0.37      2000\n",
      "weighted avg       0.37      0.38      0.37      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.42      0.38       207\n",
      "         1.0       0.29      0.43      0.35       213\n",
      "         2.0       0.23      0.23      0.23       197\n",
      "         3.0       0.20      0.22      0.21       199\n",
      "         4.0       0.32      0.23      0.27       205\n",
      "         5.0       0.23      0.19      0.21       177\n",
      "         6.0       0.34      0.38      0.36       187\n",
      "         7.0       0.30      0.20      0.24       200\n",
      "         8.0       0.44      0.41      0.42       224\n",
      "         9.0       0.35      0.35      0.35       191\n",
      "\n",
      "    accuracy                           0.31      2000\n",
      "   macro avg       0.31      0.30      0.30      2000\n",
      "weighted avg       0.31      0.31      0.30      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.55      0.50       207\n",
      "         1.0       0.42      0.54      0.48       213\n",
      "         2.0       0.27      0.21      0.24       197\n",
      "         3.0       0.28      0.27      0.28       199\n",
      "         4.0       0.36      0.28      0.32       205\n",
      "         5.0       0.32      0.22      0.26       177\n",
      "         6.0       0.38      0.44      0.41       187\n",
      "         7.0       0.45      0.38      0.41       200\n",
      "         8.0       0.53      0.59      0.56       224\n",
      "         9.0       0.42      0.48      0.45       191\n",
      "\n",
      "    accuracy                           0.40      2000\n",
      "   macro avg       0.39      0.40      0.39      2000\n",
      "weighted avg       0.39      0.40      0.39      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.51      0.50       207\n",
      "         1.0       0.42      0.56      0.48       213\n",
      "         2.0       0.27      0.30      0.29       197\n",
      "         3.0       0.33      0.28      0.30       199\n",
      "         4.0       0.39      0.30      0.34       205\n",
      "         5.0       0.30      0.23      0.26       177\n",
      "         6.0       0.39      0.44      0.41       187\n",
      "         7.0       0.48      0.27      0.34       200\n",
      "         8.0       0.48      0.60      0.53       224\n",
      "         9.0       0.40      0.47      0.43       191\n",
      "\n",
      "    accuracy                           0.40      2000\n",
      "   macro avg       0.40      0.40      0.39      2000\n",
      "weighted avg       0.40      0.40      0.39      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for CNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.45      0.48       207\n",
      "         1.0       0.36      0.61      0.45       213\n",
      "         2.0       0.34      0.22      0.27       197\n",
      "         3.0       0.27      0.28      0.28       199\n",
      "         4.0       0.33      0.54      0.41       205\n",
      "         5.0       0.28      0.12      0.17       177\n",
      "         6.0       0.37      0.33      0.35       187\n",
      "         7.0       0.42      0.36      0.39       200\n",
      "         8.0       0.51      0.57      0.54       224\n",
      "         9.0       0.49      0.32      0.39       191\n",
      "\n",
      "    accuracy                           0.39      2000\n",
      "   macro avg       0.39      0.38      0.37      2000\n",
      "weighted avg       0.39      0.39      0.38      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for RNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.53      0.49       207\n",
      "         1.0       0.42      0.54      0.48       213\n",
      "         2.0       0.27      0.35      0.30       197\n",
      "         3.0       0.28      0.20      0.24       199\n",
      "         4.0       0.40      0.20      0.27       205\n",
      "         5.0       0.25      0.19      0.21       177\n",
      "         6.0       0.40      0.44      0.42       187\n",
      "         7.0       0.32      0.35      0.33       200\n",
      "         8.0       0.48      0.51      0.50       224\n",
      "         9.0       0.41      0.40      0.41       191\n",
      "\n",
      "    accuracy                           0.38      2000\n",
      "   macro avg       0.37      0.37      0.36      2000\n",
      "weighted avg       0.37      0.38      0.37      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'feature_mtx', 'clean_y' are already defined\n",
    "X_train, X_val, y_train, y_val = train_test_split(feature_mtx_adv, clean_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Model dictionary for traditional ML models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "}\n",
    "\n",
    "# Train and evaluate each traditional ML model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy}\")\n",
    "\n",
    "# Neural Network\n",
    "model_nn = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(clean_y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model_nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_nn.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=2)\n",
    "loss, accuracy_nn = model_nn.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Neural Network Accuracy: {accuracy_nn}\")\n",
    "\n",
    "# Simplified CNN Example\n",
    "model_cnn = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1], 1)),\n",
    "    Conv1D(64, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(clean_y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_cnn.fit(X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1), y_train, epochs=10, batch_size=32, verbose=2)\n",
    "accuracy_cnn = model_cnn.evaluate(X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1), y_val, verbose=0)[1]\n",
    "print(f\"CNN Accuracy: {accuracy_cnn}\")\n",
    "\n",
    "# Simplified RNN Example\n",
    "model_rnn = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1], 1)),\n",
    "    SimpleRNN(64),\n",
    "    Dense(len(np.unique(clean_y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.fit(X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1), y_train, epochs=10, batch_size=32, verbose=2)\n",
    "accuracy_rnn = model_rnn.evaluate(X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1), y_val, verbose=0)[1]\n",
    "print(f\"RNN Accuracy: {accuracy_rnn}\")\n",
    "\n",
    "# Generate and print classification report for each model\n",
    "predictions = []\n",
    "# Collect predictions from traditional ML models\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    predictions.append((name, y_pred))\n",
    "\n",
    "# Neural Network prediction\n",
    "y_pred_nn = model_nn.predict(X_val_scaled)\n",
    "y_pred_nn = np.argmax(y_pred_nn, axis=1)  # Convert probabilities to class labels\n",
    "predictions.append((\"Neural Network\", y_pred_nn))\n",
    "\n",
    "# CNN prediction\n",
    "y_pred_cnn = model_cnn.predict(X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1))\n",
    "y_pred_cnn = np.argmax(y_pred_cnn, axis=1)\n",
    "predictions.append((\"CNN\", y_pred_cnn))\n",
    "\n",
    "# RNN prediction\n",
    "y_pred_rnn = model_rnn.predict(X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1))\n",
    "y_pred_rnn = np.argmax(y_pred_rnn, axis=1)\n",
    "predictions.append((\"RNN\", y_pred_rnn))\n",
    "\n",
    "# Print classification reports\n",
    "for name, y_pred in predictions:\n",
    "    print(f\"Classification Report for {name}:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb93b8-ff62-45d8-84b8-570b048765d3",
   "metadata": {},
   "source": [
    "#### 2.3.2.3 Tune Parameter\n",
    "80% clean label to train model (10 C-V), using 20% to validate, calculating accuracy.\n",
    "\n",
    "Then using the best model to generate labels for the rest 40000 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a10ed17-dd95-4c49-b4a9-ec25de956a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "[CV 3/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.465 total time=   5.2s\n",
      "[CV 2/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.469 total time=   5.3s\n",
      "[CV 6/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.477 total time=   5.3s\n",
      "[CV 8/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.474 total time=   5.4s\n",
      "[CV 4/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.468 total time=   5.6s\n",
      "[CV 5/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.454 total time=   5.6s\n",
      "[CV 1/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.436 total time=   5.7s\n",
      "[CV 7/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.471 total time=   6.2s\n",
      "[CV 9/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.482 total time=   5.1s\n",
      "[CV 10/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.458 total time=   5.4s\n",
      "[CV 3/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.430 total time=  11.3s\n",
      "[CV 1/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.417 total time=  11.7s\n",
      "[CV 4/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.432 total time=  11.7s\n",
      "[CV 2/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.430 total time=  12.0s\n",
      "[CV 6/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.429 total time=  11.2s\n",
      "[CV 5/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.417 total time=  11.9s\n",
      "[CV 2/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.461 total time=   3.1s\n",
      "[CV 1/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.449 total time=   3.3s\n",
      "[CV 3/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.461 total time=   3.3s\n",
      "[CV 4/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.465 total time=   3.5s\n",
      "[CV 8/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.456 total time=  11.1s\n",
      "[CV 7/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.441 total time=  12.4s\n",
      "[CV 5/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.450 total time=   3.1s\n",
      "[CV 6/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.481 total time=   3.1s\n",
      "[CV 7/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.472 total time=   3.2s\n",
      "[CV 8/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.471 total time=   3.0s\n",
      "[CV 9/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.474 total time=   2.7s\n",
      "[CV 10/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.469 total time=   2.3s\n",
      "[CV 9/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.435 total time=   9.3s\n",
      "[CV 10/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.443 total time=   9.2s\n",
      "Best Parameters found:  {'subsample': 0.3, 'n_estimators': 500, 'min_child_weight': 10, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "Validation Accuracy: 0.4685\n",
      "Full Dataset Accuracy (vs Clean Labels): 0.6571\n",
      "Full Dataset Accuracy (vs Noisy Labels): 0.5347\n",
      "Validation Precision: 0.4663861548686213\n",
      "Validation Recall: 0.4661035006705543\n",
      "Feature Importances:  [0.03472211 0.03346387 0.03167986 0.03251696 0.03273325 0.03740088\n",
      " 0.03381264 0.03192222 0.03245941 0.03191556 0.03573207 0.03923676\n",
      " 0.03362564 0.03814077 0.04596973 0.03432937 0.03486197 0.03410415\n",
      " 0.03436538 0.038156   0.03514277 0.04522689 0.04173495 0.04124387\n",
      " 0.04172355 0.09377939]\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(feature_mtx_adv, clean_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter space for Randomized Search\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.3, 0.5, 0.7],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'colsample_bytree': [0.5, 0.75, 1.0],\n",
    "    'min_child_weight': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Setup RandomizedSearchCV with verbose output\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=3, scoring='accuracy', n_jobs=-1, cv=10, random_state=42, verbose=3)\n",
    "\n",
    "# Fit the RandomizedSearchCV to find the best parameters\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions on the validation set and the entire dataset\n",
    "y_pred_val = random_search.best_estimator_.predict(X_val)\n",
    "y_pred_full = random_search.best_estimator_.predict(feature_mtx_adv)\n",
    "\n",
    "# Calculate and print accuracies\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "accuracy_full_clean = accuracy_score(clean_y, y_pred_full)\n",
    "accuracy_full_noisy = accuracy_score(noisy_y, y_pred_full)\n",
    "print(f\"Validation Accuracy: {accuracy_val}\")\n",
    "print(f\"Full Dataset Accuracy (vs Clean Labels): {accuracy_full_clean}\")\n",
    "print(f\"Full Dataset Accuracy (vs Noisy Labels): {accuracy_full_noisy}\")\n",
    "\n",
    "# Calculate and print precision and recall for the validation set\n",
    "precision_val = precision_score(y_val, y_pred_val, average='macro')\n",
    "recall_val = recall_score(y_val, y_pred_val, average='macro')\n",
    "print(f\"Validation Precision: {precision_val}\")\n",
    "print(f\"Validation Recall: {recall_val}\")\n",
    "\n",
    "# Feature importance from the best model\n",
    "feature_importances = random_search.best_estimator_.feature_importances_\n",
    "print(\"Feature Importances: \", feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20d8b3f9-c0b9-4049-aaf7-058d24350a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model type: <class 'xgboost.sklearn.XGBClassifier'>\n",
      "Best parameters found: {'subsample': 0.3, 'n_estimators': 500, 'min_child_weight': 10, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model type:\", type(random_search.best_estimator_))\n",
    "print(\"Best parameters found:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e36f6-df69-4e29-b040-9781fe64a366",
   "metadata": {},
   "source": [
    "#### 2.3.2.4 Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b552f41d-1c00-4f2f-97f3-6acc5613e8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved as 'best_xgboost_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming the rest of your code is unchanged and comes before this:\n",
    "\n",
    "# Save the best model\n",
    "best_model = random_search.best_estimator_\n",
    "joblib.dump(best_model, '../best_xgboost_model.pkl')\n",
    "\n",
    "print(\"Best model saved as 'best_xgboost_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694ca1c-da4d-4123-a2f7-d606d11d8700",
   "metadata": {},
   "source": [
    "#### 2.3.2.5 Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c05c470-ad71-4978-a0dd-b8143ffdcc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming you have your trained model 'best_model'\n",
    "with open('../best_xgboost_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "with open('../best_xgboost_model.pkl', 'rb') as file:\n",
    "    best_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e123e750-260e-4419-a3dd-747993392a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Hyperparameters:\n",
      "{'objective': 'multi:softprob', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.5, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.1, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': 10, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 500, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.3, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n",
      "Feature Importances:\n",
      "[0.03472211 0.03346387 0.03167986 0.03251696 0.03273325 0.03740088\n",
      " 0.03381264 0.03192222 0.03245941 0.03191556 0.03573207 0.03923676\n",
      " 0.03362564 0.03814077 0.04596973 0.03432937 0.03486197 0.03410415\n",
      " 0.03436538 0.038156   0.03514277 0.04522689 0.04173495 0.04124387\n",
      " 0.04172355 0.09377939]\n",
      "Model Dump:\n",
      "0:[f11<102] yes=1,no=2,missing=2\n",
      "\t1:[f25<2] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=0.239195228\n",
      "\t\t4:[f12<97] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=0.185039386\n",
      "\t\t\t8:leaf=0.0775673687\n",
      "\t2:[f25<1] yes=5,no=6,missing=6\n",
      "\t\t5:[f10<139] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=0.203903109\n",
      "\t\t\t10:leaf=0.0152198402\n",
      "\t\t6:[f21<133.469727] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.0444501005\n",
      "\t\t\t12:leaf=-0.00280899089\n",
      "\n",
      "0:[f25<2] yes=1,no=2,missing=2\n",
      "\t1:[f25<1] yes=3,no=4,missing=4\n",
      "\t\t3:[f0<126] yes=7,no=8,missing=8\n",
      "\t\t\t7:leaf=-0.050105121\n",
      "\t\t\t8:leaf=0.00372208259\n",
      "\t\t4:[f16<42.9115486] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=-0.0249569733\n",
      "\t\t\t10:leaf=0.220180899\n",
      "\t2:[f19<47.1229858] yes=5,no=6,missing=6\n",
      "\t\t5:[f19<39.7078552] yes=11,no=12,missing=12\n",
      "\t\t\t11:leaf=-0.0538825579\n",
      "\t\t\t12:leaf=-0.0298778508\n",
      "\t\t6:[f0<81] yes=13,no=14,missing=14\n",
      "\t\t\t13:leaf=-0.0231277552\n",
      "\t\t\t14:leaf=0.00794144999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print hyperparameters of the model\n",
    "print(\"Model Hyperparameters:\")\n",
    "print(best_model.get_params())\n",
    "# Print feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(best_model.feature_importances_)\n",
    "# Dump model\n",
    "print(\"Model Dump:\")\n",
    "dump_list = best_model.get_booster().get_dump()\n",
    "for tree in dump_list[:2]:  # Just print the first two trees\n",
    "    print(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e520805",
   "metadata": {},
   "source": [
    "## 2.4 Model III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61abdce",
   "metadata": {},
   "source": [
    "### 2.4.1 Add one more feature: the predicted label from Model II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39655133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_mtx_3 = np.empty((n_train_img,27))\n",
    "new_feature = best_model.predict(feature_mtx_adv)\n",
    "new_feature_reshaped = new_feature.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d286cfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 27)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mtx_new = np.concatenate((feature_mtx_adv, new_feature_reshaped), axis=1)\n",
    "feature_mtx_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae0e619",
   "metadata": {},
   "source": [
    "### 2.4.2 model selection\n",
    "Then repeat again to choose the most appropirate technique for model III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67417c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.462\n",
      "XGBoost Accuracy: 0.467\n",
      "Logistic Regression Accuracy: 0.4045\n",
      "KNN Accuracy: 0.351\n",
      "SVM Accuracy: 0.44\n",
      "Epoch 1/10\n",
      "250/250 - 1s - 3ms/step - accuracy: 0.3758 - loss: 1.8442\n",
      "Epoch 2/10\n",
      "250/250 - 0s - 542us/step - accuracy: 0.4835 - loss: 1.6163\n",
      "Epoch 3/10\n",
      "250/250 - 0s - 482us/step - accuracy: 0.5395 - loss: 1.5311\n",
      "Epoch 4/10\n",
      "250/250 - 0s - 502us/step - accuracy: 0.5635 - loss: 1.4769\n",
      "Epoch 5/10\n",
      "250/250 - 0s - 487us/step - accuracy: 0.5934 - loss: 1.4333\n",
      "Epoch 6/10\n",
      "250/250 - 0s - 500us/step - accuracy: 0.6047 - loss: 1.4050\n",
      "Epoch 7/10\n",
      "250/250 - 0s - 504us/step - accuracy: 0.6146 - loss: 1.3791\n",
      "Epoch 8/10\n",
      "250/250 - 0s - 536us/step - accuracy: 0.6237 - loss: 1.3591\n",
      "Epoch 9/10\n",
      "250/250 - 0s - 476us/step - accuracy: 0.6298 - loss: 1.3385\n",
      "Epoch 10/10\n",
      "250/250 - 0s - 514us/step - accuracy: 0.6384 - loss: 1.3197\n",
      "Neural Network Accuracy: 0.4490000009536743\n",
      "Epoch 1/10\n",
      "250/250 - 1s - 2ms/step - accuracy: 0.2837 - loss: 1.9825\n",
      "Epoch 2/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3487 - loss: 1.8283\n",
      "Epoch 3/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3568 - loss: 1.7871\n",
      "Epoch 4/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3700 - loss: 1.7615\n",
      "Epoch 5/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3750 - loss: 1.7419\n",
      "Epoch 6/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3821 - loss: 1.7273\n",
      "Epoch 7/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3861 - loss: 1.7085\n",
      "Epoch 8/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3956 - loss: 1.6956\n",
      "Epoch 9/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.3971 - loss: 1.6849\n",
      "Epoch 10/10\n",
      "250/250 - 0s - 1ms/step - accuracy: 0.4074 - loss: 1.6715\n",
      "CNN Accuracy: 0.39100000262260437\n",
      "Epoch 1/10\n",
      "250/250 - 1s - 3ms/step - accuracy: 0.3745 - loss: 1.8435\n",
      "Epoch 2/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.4460 - loss: 1.7006\n",
      "Epoch 3/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.4601 - loss: 1.6721\n",
      "Epoch 4/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.4703 - loss: 1.6533\n",
      "Epoch 5/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.4708 - loss: 1.6358\n",
      "Epoch 6/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.4810 - loss: 1.6199\n",
      "Epoch 7/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.4812 - loss: 1.6071\n",
      "Epoch 8/10\n",
      "250/250 - 1s - 2ms/step - accuracy: 0.4915 - loss: 1.5908\n",
      "Epoch 9/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.4988 - loss: 1.5771\n",
      "Epoch 10/10\n",
      "250/250 - 0s - 2ms/step - accuracy: 0.5061 - loss: 1.5618\n",
      "RNN Accuracy: 0.39750000834465027\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.57      0.54       207\n",
      "         1.0       0.48      0.46      0.47       213\n",
      "         2.0       0.45      0.43      0.44       197\n",
      "         3.0       0.41      0.35      0.38       199\n",
      "         4.0       0.54      0.47      0.50       205\n",
      "         5.0       0.36      0.34      0.35       177\n",
      "         6.0       0.45      0.47      0.46       187\n",
      "         7.0       0.41      0.46      0.43       200\n",
      "         8.0       0.53      0.54      0.53       224\n",
      "         9.0       0.44      0.50      0.47       191\n",
      "\n",
      "    accuracy                           0.46      2000\n",
      "   macro avg       0.46      0.46      0.46      2000\n",
      "weighted avg       0.46      0.46      0.46      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.57      0.54       207\n",
      "         1.0       0.49      0.46      0.48       213\n",
      "         2.0       0.46      0.43      0.44       197\n",
      "         3.0       0.44      0.37      0.40       199\n",
      "         4.0       0.54      0.49      0.51       205\n",
      "         5.0       0.38      0.36      0.37       177\n",
      "         6.0       0.44      0.47      0.45       187\n",
      "         7.0       0.42      0.46      0.43       200\n",
      "         8.0       0.53      0.54      0.53       224\n",
      "         9.0       0.44      0.50      0.47       191\n",
      "\n",
      "    accuracy                           0.47      2000\n",
      "   macro avg       0.46      0.46      0.46      2000\n",
      "weighted avg       0.47      0.47      0.47      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.55      0.49       207\n",
      "         1.0       0.39      0.46      0.42       213\n",
      "         2.0       0.36      0.31      0.33       197\n",
      "         3.0       0.33      0.26      0.29       199\n",
      "         4.0       0.48      0.38      0.42       205\n",
      "         5.0       0.27      0.16      0.20       177\n",
      "         6.0       0.37      0.45      0.41       187\n",
      "         7.0       0.42      0.35      0.38       200\n",
      "         8.0       0.52      0.53      0.52       224\n",
      "         9.0       0.39      0.55      0.46       191\n",
      "\n",
      "    accuracy                           0.40      2000\n",
      "   macro avg       0.40      0.40      0.39      2000\n",
      "weighted avg       0.40      0.40      0.40      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.47      0.44       207\n",
      "         1.0       0.34      0.41      0.37       213\n",
      "         2.0       0.25      0.25      0.25       197\n",
      "         3.0       0.22      0.26      0.24       199\n",
      "         4.0       0.40      0.28      0.33       205\n",
      "         5.0       0.25      0.22      0.23       177\n",
      "         6.0       0.35      0.41      0.38       187\n",
      "         7.0       0.35      0.26      0.29       200\n",
      "         8.0       0.53      0.50      0.51       224\n",
      "         9.0       0.39      0.42      0.41       191\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.35      0.35      0.35      2000\n",
      "weighted avg       0.35      0.35      0.35      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.59      0.52       207\n",
      "         1.0       0.46      0.45      0.45       213\n",
      "         2.0       0.42      0.31      0.36       197\n",
      "         3.0       0.33      0.32      0.32       199\n",
      "         4.0       0.51      0.42      0.46       205\n",
      "         5.0       0.34      0.30      0.32       177\n",
      "         6.0       0.41      0.50      0.45       187\n",
      "         7.0       0.45      0.40      0.43       200\n",
      "         8.0       0.55      0.54      0.54       224\n",
      "         9.0       0.43      0.54      0.48       191\n",
      "\n",
      "    accuracy                           0.44      2000\n",
      "   macro avg       0.44      0.44      0.43      2000\n",
      "weighted avg       0.44      0.44      0.44      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.53      0.51       207\n",
      "         1.0       0.46      0.45      0.45       213\n",
      "         2.0       0.42      0.39      0.40       197\n",
      "         3.0       0.39      0.35      0.37       199\n",
      "         4.0       0.53      0.47      0.50       205\n",
      "         5.0       0.33      0.32      0.32       177\n",
      "         6.0       0.43      0.49      0.46       187\n",
      "         7.0       0.42      0.43      0.42       200\n",
      "         8.0       0.55      0.55      0.55       224\n",
      "         9.0       0.44      0.49      0.46       191\n",
      "\n",
      "    accuracy                           0.45      2000\n",
      "   macro avg       0.45      0.45      0.45      2000\n",
      "weighted avg       0.45      0.45      0.45      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for CNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.49      0.48       207\n",
      "         1.0       0.44      0.49      0.47       213\n",
      "         2.0       0.26      0.28      0.27       197\n",
      "         3.0       0.32      0.22      0.26       199\n",
      "         4.0       0.44      0.21      0.28       205\n",
      "         5.0       0.28      0.17      0.21       177\n",
      "         6.0       0.35      0.49      0.41       187\n",
      "         7.0       0.45      0.28      0.34       200\n",
      "         8.0       0.47      0.67      0.55       224\n",
      "         9.0       0.36      0.57      0.44       191\n",
      "\n",
      "    accuracy                           0.39      2000\n",
      "   macro avg       0.39      0.39      0.37      2000\n",
      "weighted avg       0.39      0.39      0.38      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Classification Report for RNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.58      0.51       207\n",
      "         1.0       0.45      0.45      0.45       213\n",
      "         2.0       0.36      0.27      0.31       197\n",
      "         3.0       0.29      0.24      0.26       199\n",
      "         4.0       0.41      0.43      0.42       205\n",
      "         5.0       0.24      0.18      0.21       177\n",
      "         6.0       0.34      0.48      0.40       187\n",
      "         7.0       0.34      0.28      0.31       200\n",
      "         8.0       0.50      0.54      0.52       224\n",
      "         9.0       0.47      0.49      0.48       191\n",
      "\n",
      "    accuracy                           0.40      2000\n",
      "   macro avg       0.39      0.39      0.39      2000\n",
      "weighted avg       0.39      0.40      0.39      2000\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try again for each model to find the optimal\n",
    "X_train, X_val, y_train, y_val = train_test_split(feature_mtx_new, clean_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Model dictionary for traditional ML models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "}\n",
    "\n",
    "# Train and evaluate each traditional ML model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy}\")\n",
    "\n",
    "# Neural Network\n",
    "model_nn = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(clean_y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model_nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_nn.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=2)\n",
    "loss, accuracy_nn = model_nn.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "print(f\"Neural Network Accuracy: {accuracy_nn}\")\n",
    "\n",
    "# Simplified CNN Example\n",
    "model_cnn = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1], 1)),\n",
    "    Conv1D(64, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(clean_y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_cnn.fit(X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1), y_train, epochs=10, batch_size=32, verbose=2)\n",
    "accuracy_cnn = model_cnn.evaluate(X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1), y_val, verbose=0)[1]\n",
    "print(f\"CNN Accuracy: {accuracy_cnn}\")\n",
    "\n",
    "# Simplified RNN Example\n",
    "model_rnn = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1], 1)),\n",
    "    SimpleRNN(64),\n",
    "    Dense(len(np.unique(clean_y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.fit(X_train_scaled.reshape(-1, X_train_scaled.shape[1], 1), y_train, epochs=10, batch_size=32, verbose=2)\n",
    "accuracy_rnn = model_rnn.evaluate(X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1), y_val, verbose=0)[1]\n",
    "print(f\"RNN Accuracy: {accuracy_rnn}\")\n",
    "\n",
    "# Generate and print classification report for each model\n",
    "predictions = []\n",
    "# Collect predictions from traditional ML models\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    predictions.append((name, y_pred))\n",
    "\n",
    "# Neural Network prediction\n",
    "y_pred_nn = model_nn.predict(X_val_scaled)\n",
    "y_pred_nn = np.argmax(y_pred_nn, axis=1)  # Convert probabilities to class labels\n",
    "predictions.append((\"Neural Network\", y_pred_nn))\n",
    "\n",
    "# CNN prediction\n",
    "y_pred_cnn = model_cnn.predict(X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1))\n",
    "y_pred_cnn = np.argmax(y_pred_cnn, axis=1)\n",
    "predictions.append((\"CNN\", y_pred_cnn))\n",
    "\n",
    "# RNN prediction\n",
    "y_pred_rnn = model_rnn.predict(X_val_scaled.reshape(-1, X_val_scaled.shape[1], 1))\n",
    "y_pred_rnn = np.argmax(y_pred_rnn, axis=1)\n",
    "predictions.append((\"RNN\", y_pred_rnn))\n",
    "\n",
    "# Print classification reports\n",
    "for name, y_pred in predictions:\n",
    "    print(f\"Classification Report for {name}:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124830d1",
   "metadata": {},
   "source": [
    "Here, the XGBoost is the best in the classification report, approximately 47%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e340c",
   "metadata": {},
   "source": [
    "### 2.4.3 Hyperparamter tuning\n",
    "Then, we can try to do hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "116b580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "[CV 5/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.703 total time=   5.2s\n",
      "[CV 8/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.706 total time=   5.2s\n",
      "[CV 7/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.708 total time=   5.3s\n",
      "[CV 4/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.719 total time=   5.3s\n",
      "[CV 2/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.685 total time=   5.4s\n",
      "[CV 1/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.696 total time=   5.4s\n",
      "[CV 6/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.731 total time=   5.6s\n",
      "[CV 3/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.666 total time=   6.1s\n",
      "[CV 10/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.696 total time=   5.2s\n",
      "[CV 9/10] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, min_child_weight=10, n_estimators=500, subsample=0.3;, score=0.694 total time=   5.5s\n",
      "[CV 1/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.641 total time=  10.6s\n",
      "[CV 4/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.672 total time=  11.0s\n",
      "[CV 5/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.646 total time=  11.3s\n",
      "[CV 2/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.619 total time=  11.6s\n",
      "[CV 3/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.618 total time=  11.6s\n",
      "[CV 6/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.652 total time=  10.9s\n",
      "[CV 3/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.669 total time=   2.6s\n",
      "[CV 2/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.693 total time=   2.9s\n",
      "[CV 4/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.720 total time=   3.1s\n",
      "[CV 1/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.698 total time=   3.3s\n",
      "[CV 8/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.656 total time=  11.7s\n",
      "[CV 7/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.640 total time=  11.8s\n",
      "[CV 5/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.705 total time=   2.9s\n",
      "[CV 6/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.739 total time=   3.1s\n",
      "[CV 7/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.710 total time=   3.1s\n",
      "[CV 8/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.713 total time=   3.4s\n",
      "[CV 10/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.700 total time=   2.6s\n",
      "[CV 9/10] END colsample_bytree=0.75, learning_rate=0.01, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.3;, score=0.698 total time=   2.7s\n",
      "[CV 9/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.639 total time=  10.1s\n",
      "[CV 10/10] END colsample_bytree=0.75, learning_rate=0.3, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.3;, score=0.626 total time=   9.7s\n",
      "Best Parameters found:  {'subsample': 0.3, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bytree': 0.75}\n",
      "Validation Accuracy: 0.4685\n",
      "Full Dataset Accuracy (vs Clean Labels): 0.6571\n",
      "Full Dataset Accuracy (vs Noisy Labels): 0.5347\n",
      "Validation Precision: 0.4663861548686213\n",
      "Validation Recall: 0.4661035006705543\n",
      "Feature Importances:  [0.01424554 0.01347973 0.0131859  0.01237305 0.01385991 0.01507869\n",
      " 0.01354683 0.01324743 0.01358757 0.01422248 0.01421979 0.02170916\n",
      " 0.01396993 0.01691389 0.03788542 0.01464    0.01852136 0.01458933\n",
      " 0.01399197 0.01645084 0.01544725 0.02927279 0.02812848 0.01793764\n",
      " 0.01904718 0.06265251 0.5077953 ]\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(feature_mtx_new, clean_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter space for Randomized Search\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.3, 0.5, 0.7],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'colsample_bytree': [0.5, 0.75, 1.0],\n",
    "    'min_child_weight': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Setup RandomizedSearchCV with verbose output\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=3, scoring='accuracy', n_jobs=-1, cv=10, random_state=42, verbose=3)\n",
    "\n",
    "# Fit the RandomizedSearchCV to find the best parameters\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions on the validation set and the entire dataset\n",
    "y_pred_val = random_search.best_estimator_.predict(X_val)\n",
    "y_pred_full = random_search.best_estimator_.predict(feature_mtx_new)\n",
    "\n",
    "# Calculate and print accuracies\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "accuracy_full_clean = accuracy_score(clean_y, y_pred_full)\n",
    "accuracy_full_noisy = accuracy_score(noisy_y, y_pred_full)\n",
    "print(f\"Validation Accuracy: {accuracy_val}\")\n",
    "print(f\"Full Dataset Accuracy (vs Clean Labels): {accuracy_full_clean}\")\n",
    "print(f\"Full Dataset Accuracy (vs Noisy Labels): {accuracy_full_noisy}\")\n",
    "\n",
    "# Calculate and print precision and recall for the validation set\n",
    "precision_val = precision_score(y_val, y_pred_val, average='macro')\n",
    "recall_val = recall_score(y_val, y_pred_val, average='macro')\n",
    "print(f\"Validation Precision: {precision_val}\")\n",
    "print(f\"Validation Recall: {recall_val}\")\n",
    "\n",
    "# Feature importance from the best model\n",
    "feature_importances = random_search.best_estimator_.feature_importances_\n",
    "print(\"Feature Importances: \", feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83833df",
   "metadata": {},
   "source": [
    "### 2.4.4 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24dbf92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved as 'best_model3.pkl'\n"
     ]
    }
   ],
   "source": [
    "best_model3 = random_search.best_estimator_\n",
    "joblib.dump(best_model3, '../best_model3.pkl')\n",
    "\n",
    "print(\"Best model saved as 'best_model3.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb47df",
   "metadata": {},
   "source": [
    "### 2.4.5 Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46947309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming you have your trained model 'best_model'\n",
    "with open('../best_model3.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model3, file)\n",
    "with open('../best_model3.pkl', 'rb') as file:\n",
    "    best_model3 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e778adec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Hyperparameters:\n",
      "{'objective': 'multi:softprob', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.75, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': 'logloss', 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 5, 'max_leaves': None, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.3, 'tree_method': None, 'validate_parameters': None, 'verbosity': None, 'use_label_encoder': False}\n",
      "Feature Importances:\n",
      "[0.01424554 0.01347973 0.0131859  0.01237305 0.01385991 0.01507869\n",
      " 0.01354683 0.01324743 0.01358757 0.01422248 0.01421979 0.02170916\n",
      " 0.01396993 0.01691389 0.03788542 0.01464    0.01852136 0.01458933\n",
      " 0.01399197 0.01645084 0.01544725 0.02927279 0.02812848 0.01793764\n",
      " 0.01904718 0.06265251 0.5077953 ]\n",
      "Model Dump:\n",
      "0:[f26<1] yes=1,no=2,missing=2\n",
      "\t1:[f18<198.191406] yes=3,no=4,missing=4\n",
      "\t\t3:[f5<1] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f19<24.7442284] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:leaf=0.026047904\n",
      "\t\t\t\t16:leaf=0.00132743351\n",
      "\t\t\t8:leaf=0.037506789\n",
      "\t\t4:[f11<49] yes=9,no=10,missing=10\n",
      "\t\t\t9:leaf=0.0197986569\n",
      "\t\t\t10:leaf=0.00192307681\n",
      "\t2:[f21<133.469727] yes=5,no=6,missing=6\n",
      "\t\t5:[f17<1.62653816] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f20<-1.77177382] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:leaf=0.00132743351\n",
      "\t\t\t\t18:[f1<18] yes=25,no=26,missing=26\n",
      "\t\t\t\t\t25:leaf=-0.000898203754\n",
      "\t\t\t\t\t26:leaf=-0.00508118747\n",
      "\t\t\t12:[f22<39.889164] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:leaf=-0.00412371149\n",
      "\t\t\t\t20:leaf=0.0067307693\n",
      "\t\t6:[f13<596] yes=13,no=14,missing=14\n",
      "\t\t\t13:[f0<174] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:[f26<7] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=-0.00456570182\n",
      "\t\t\t\t\t28:leaf=-0.00196304871\n",
      "\t\t\t\t22:[f13<133] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=0.00618556654\n",
      "\t\t\t\t\t30:leaf=-0.00205479469\n",
      "\t\t\t14:[f21<161.233398] yes=23,no=24,missing=24\n",
      "\t\t\t\t23:leaf=-0.0037974685\n",
      "\t\t\t\t24:[f1<89] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=0.0115384609\n",
      "\t\t\t\t\t32:leaf=0.00192307681\n",
      "\n",
      "0:[f26<2] yes=1,no=2,missing=2\n",
      "\t1:[f26<1] yes=3,no=4,missing=4\n",
      "\t\t3:leaf=-0.00521201408\n",
      "\t\t4:[f14<2] yes=7,no=8,missing=8\n",
      "\t\t\t7:[f3<154] yes=13,no=14,missing=14\n",
      "\t\t\t\t13:leaf=0.021311475\n",
      "\t\t\t\t14:leaf=0.000819672015\n",
      "\t\t\t8:leaf=0.0353379734\n",
      "\t2:[f24<204.256088] yes=5,no=6,missing=6\n",
      "\t\t5:[f22<43.6823158] yes=9,no=10,missing=10\n",
      "\t\t\t9:[f21<30.1787109] yes=15,no=16,missing=16\n",
      "\t\t\t\t15:[f0<300] yes=23,no=24,missing=24\n",
      "\t\t\t\t\t23:leaf=0.00192307681\n",
      "\t\t\t\t\t24:leaf=-0.00288461521\n",
      "\t\t\t\t16:[f1<663] yes=25,no=26,missing=26\n",
      "\t\t\t\t\t25:leaf=-0.00550320419\n",
      "\t\t\t\t\t26:leaf=-0.00331412139\n",
      "\t\t\t10:[f12<457] yes=17,no=18,missing=18\n",
      "\t\t\t\t17:[f4<1] yes=27,no=28,missing=28\n",
      "\t\t\t\t\t27:leaf=0.0001246881\n",
      "\t\t\t\t\t28:leaf=-0.00475382013\n",
      "\t\t\t\t18:[f8<185] yes=29,no=30,missing=30\n",
      "\t\t\t\t\t29:leaf=0.0101769911\n",
      "\t\t\t\t\t30:leaf=-0.00389221567\n",
      "\t\t6:[f22<62.3399391] yes=11,no=12,missing=12\n",
      "\t\t\t11:[f24<262.435913] yes=19,no=20,missing=20\n",
      "\t\t\t\t19:[f0<128] yes=31,no=32,missing=32\n",
      "\t\t\t\t\t31:leaf=-0.00480321655\n",
      "\t\t\t\t\t32:leaf=-0.00201499555\n",
      "\t\t\t\t20:[f11<351] yes=33,no=34,missing=34\n",
      "\t\t\t\t\t33:leaf=-0.00405405415\n",
      "\t\t\t\t\t34:leaf=0.00714285718\n",
      "\t\t\t12:[f11<416] yes=21,no=22,missing=22\n",
      "\t\t\t\t21:[f4<238] yes=35,no=36,missing=36\n",
      "\t\t\t\t\t35:leaf=0.000814332045\n",
      "\t\t\t\t\t36:leaf=-0.00383663387\n",
      "\t\t\t\t22:[f17<0.324031502] yes=37,no=38,missing=38\n",
      "\t\t\t\t\t37:leaf=0.000381679274\n",
      "\t\t\t\t\t38:leaf=0.0163461547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print hyperparameters of the model\n",
    "print(\"Model Hyperparameters:\")\n",
    "print(best_model3.get_params())\n",
    "# Print feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(best_model3.feature_importances_)\n",
    "# Dump model\n",
    "print(\"Model Dump:\")\n",
    "dump_list = best_model3.get_booster().get_dump()\n",
    "for tree in dump_list[:2]:  # Just print the first two trees\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cd3c7",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a62ec",
   "metadata": {},
   "source": [
    "For assessment, we will evaluate your final model on a hidden test dataset with clean labels by the `evaluation` function defined as follows. Although you will not have the access to the test set, the function would be useful for the model developments. For example, you can split the small training set, using one portion for weakly supervised learning and the other for validation purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdef08fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "def evaluation(model, test_labels, test_imgs):\n",
    "    y_true = test_labels\n",
    "    y_pred = []\n",
    "    for image in test_imgs:\n",
    "        y_pred.append(model(image))\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "255c462b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "../data/data/test_labels.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# [DO NOT MODIFY THIS CELL]\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# This is the code for evaluating the prediction performance on a testset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# You will get an error if running this cell, as you do not have the testset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Nonetheless, you can create your own validation set to run the evlauation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m----> 6\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/data/test_labels.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m test_imgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n_test,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_test):\n",
      "File \u001b[0;32m~/miniconda3/envs/5243_proj3/lib/python3.9/site-packages/numpy/lib/npyio.py:1980\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[1;32m   1978\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1980\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1981\u001b[0m     fid_ctx \u001b[38;5;241m=\u001b[39m contextlib\u001b[38;5;241m.\u001b[39mclosing(fid)\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/5243_proj3/lib/python3.9/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/5243_proj3/lib/python3.9/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ../data/data/test_labels.csv not found."
     ]
    }
   ],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# This is the code for evaluating the prediction performance on a testset\n",
    "# You will get an error if running this cell, as you do not have the testset\n",
    "# Nonetheless, you can create your own validation set to run the evlauation\n",
    "n_test = 10000\n",
    "test_labels = np.genfromtxt('../data/test_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "test_imgs = np.empty((n_test,32,32,3))\n",
    "for i in range(n_test):\n",
    "    img_fn = f'../data/test_images/test{i+1:05d}.png'\n",
    "    test_imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "evaluation(baseline_model, test_labels, test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496eb12d",
   "metadata": {},
   "source": [
    "The overall accuracy is $0.24$, which is better than random guess (which should have a accuracy around $0.10$). For the project, you should try to improve the performance by the following strategies:\n",
    "\n",
    "- Consider a better choice of model architectures, hyperparameters, or training scheme for the predictive model;\n",
    "- Use both `clean_noisy_trainset` and `noisy_trainset` for model training via **weakly supervised learning** methods. One possible solution is to train a \"label-correction\" model using the former, correct the labels in the latter, and train the final predictive model using the corrected dataset.\n",
    "- Apply techniques such as $k$-fold cross validation to avoid overfitting;\n",
    "- Any other reasonable strategies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
